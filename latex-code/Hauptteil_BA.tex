\chapter{Virtualisierung}\label{chap:Virt}
Als Virtualisierung bezeichnet man in der Informationstechnologie das Zusammenfassen mehrerer unterschiedlicher Ressourcen zu einem Gesamtsystem, auf dem mehrere isolierte Systeme gleichzeitig betrieben werden können. Aus logischer Sicht erscheint dieses System dem Anwender als homogen, obwohl es eine virtuelle Verknüpfung einzelner Komponenten zu einer gemeinsamen Umgebung ist. Das Ziel einer solchen Lösung ist die bedarfsgerechte Nutzung der Ressourcen und die damit verbundene Auslastungsoptimierung vorhandener Hardware.~\cite[S.~411]{Bengel2015}\medskip\\
Der Begriff \textit{Virtualisierung} beschreibt dabei die Gesamtheit der Konzepte und Technologien, welche für die dynamische Auslastungsoptimierung von Ressourcen durch die Abstraktion der Software von der Hardware gedacht sind. \cite[S.~253]{Baun2020}\medskip\\
Das Grundkonzept der Virtualisierung besteht bereits seit den 1960er Jahren, als Administratoren mehrere virtuelle Betriebssysteminstanzen parallel betrieben. Seit diesen anfänglichen Virtualisierungsversuchen, die damals auf einem sog. Mainframe installiert wurden, hat sich in der globalen Virtualisierungsentwicklung einiges getan. Vor allem die Möglichkeit, auch die Standardhardware in der x86-Architektur virtualisieren zu können, eröffnete neue Wege in der Windows- aber auch in der Linux-Serverlandschaft. Hinzu kommt, dass Unternehmen ihre laufenden Administrationskosten reduzieren können, wenn sie ihre Applikationen virtualisiert über eine zentrale Serverfarm bereitstellen. Neben der serverseitigen Virtualisierung erlangt auch die Virtualisierung von Desktops im Unternehmensumfeld immer größerer Bedeutung, weil durch die Entkopplung der Benutzeroberfläche vom Endgerät die administrative Verwaltung dieser Desktops zentralisiert und damit vereinfacht werden kann.
\cite[S.~72]{2010}
\section{Aufbau und Struktur}
Bei der Virtualisierung gibt es viele unterschiedliche Konzepte und Varianten. Der Fokus in diesem Abschnitt soll auf der vollständigen serverbasierten Virtualisierung liegen, bei der auf einem physischen Server ein sog. Hypervisor den Betrieb der virtuellen Maschinen dieses Servers verwaltet. Nachdem die einzelnen Komponenten der Virtualisierungsvariante in den folgenden Unterabschnitten vorgestellt wurden, werden diese theoretischen Grundlagen am Beispiel der Virtualisierungslösung von VMware erläutert.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Images/0aa0d423-27cb-4626-a5e1-8030c9a8b66d.jpg}\caption[Schema zur Virtualisierung]{Schema zur Virtualisierung~\cite[S.~9]{SiemensIndustryOnlineSupport2018}}
    \label{fig:SchemaVirt}
\end{figure}
Das System der Virtualisierung wird im Überblick in \autoref{fig:SchemaVirt} dargestellt. Aus einem oder mehreren realen Systemen (linke Seite der Abbildung), auf denen ein Betriebssystem mit mehreren Applikationen läuft, wird ein virtuelles Gesamtsystem (rechte Seite der Abbildung). Dieses Gesamtsystem greift auf die gemeinsame Hardware zu und stellt den Applikationen eine mit der Realität übereinstimmende Umgebung zur Verfügung.\medskip\\
Der wesentliche Grund für eine Virtualisierung ist meist die flexible Nutzung der vorhandenen Hardware. Die Ressourcen eines Servers können im Bedarfsfall zwischen den virtuellen Maschinen verteilt werden, wenn z.B. eine der virtuellen Maschinen permanent an der Leistungsgrenze arbeitet, eine andere aber den Großteil der Zeit im Ruhezustand verbringt. Die überschüssigen Ressourcen werden also nicht dort genutzt, wo sie ursprünglich konfiguriert wurden, sondern wo sie im Moment tatsächlich benötigt werden.
\cite[S.~38 ff.]{Wohrmann2018}\medskip\\
Neben der Flexibilität der Ressourcen ist der Zugriff auf die Hardware ein entscheidender Punkt der Virtualisierung. Die virtuellen Ressourcen mehrerer Server können als gemeinsame Komponenten an die virtuellen Maschinen gegeben werden, wodurch die Ressourcen als homogen erscheinen. Den Anwender interessiert beispielsweise nur die wahrgenommene Kapazität einer virtuellen Festplatte, die aber in der Realität durch mehrere Festplatten auf unterschiedlichen Servern abgebildet wird. Dadurch wird auch der Austausch der realen Hardware ermöglicht, ohne Einfluss auf die virtuellen Ressourcen zu nehmen. \cite[S.~106 f.]{Betzler2007}
\subsection{Host}
Als Virtualisierungshost (kurz Host) wird ein physischer Server bezeichnet, der die Hardware für virtuelle Prozesse bereitstellt. Auf diesem Host sollen gleichzeitig mehrere Gastsysteme betrieben werden, die man auch als virtuelle Maschinen bezeichnet. Um diese virtuellen Maschinen der physischen Peripherie zuordnen zu können, wird ein Hypervisor als zwischengelagerter Vermittler benötigt, der genauer im nächsten Abschnitt beschrieben wird. Für eine gleichzeitige Verwaltung mehrerer Hosts wird eine Servermanagementsoftware benötigt. Die Verfügbarkeit der Rechenleistung ist das essentielle Auswahlkriterium eines physischen Servers. Weil der Server seine Hardware speziell bei zeitkritischen Anforderungen dauerhaft zur Verfügung stellen muss und es dadurch zu einer ununterbrochenen Betriebszeit kommt, müssen die wichtigen Komponenten redundant ausgeführt sein. Der Host sollte also im Idealfall mit doppelter Spannungsversorgung, mehr als einem Netzwerkadapter und mehreren Festplatten ausgestattet sein. Für die Kühlung der Prozessoren sollte ausreichend Luftstrom im Gehäuse erzeugt werden, wofür meist mehrere Lüfter verwendet werden. Der Server wird idealerweise in einem separaten Raum platziert, um eine definierte Umgebungstemperatur bereitzustellen und um den Geräuschpegel, der aufgrund der aktiven Kühlung mit Lüftern entsteht, für die Umgebung zu minimieren.
Grundsätzlich kann jeder Rechner als Virtualisierungshost dienen, sofern dessen Prozessor virtualisierungfähig ist. Die hohen Leistungsansprüche an die Hardware schließen jedoch meist die Standardhardware aus, weshalb bei Virtualisierungssystemen auf speziell konfigurierte Serverrechner von Firmen wie z.B. HP oder Dell zurückgegriffen wird. \cite[S.~54]{Wohrmann2018}

\subsection{Hypervisor}
Als Hypervisor wird die Softwareschicht bezeichnet, die zwischen den virtuellen Maschinen und der Hardware angesiedelt ist. Der veraltete Begriff \textit{Virtual Machine Manager} beschreibt den Zweck eines Hypervisors, das Verwalten der virtuelle Maschinen, wörtlich. Ein Hypervisor ist der Manager, der die Interaktionen der virtuellen Maschinen mit der zugrundeliegenden Hardware koordiniert. Ohne diese verwaltende Instanz würden die Betriebssysteme der virtuellen Maschinen um den Hardwarezugriff konkurrieren und damit ein Chaos auslösen, da eine gleichzeitige Nutzung nicht möglich ist.~\cite[S.~41]{Portnoy2012}\medskip\\
Popek und Goldberg haben im Jahr 1974 die formalen Voraussetzungen für die Virtualisierung anhand der Eigenschaften des Hypervisors definiert, die mit den folgenden drei Aspekten zusammengefasst werden können:
\begin{compactitem}
    \item Der virtuellen Maschine eine Umgebung zur Verfügung stellen, die mit der physikalischen Umgebung identisch ist
    \item Minimale Performancekosten in der Bereitstellung der Umgebung haben
    \item System-Ressourcen vollständig kontrollieren \cite[S.~47 ff.]{Portnoy2012}
\end{compactitem}
Im \myRef{VirtReq} sind die drei Theoreme aus dem Originaltext aufgeführt.\medskip\\
Bei Hypervisoren unterscheidet man grundsätzlich zwischen zwei Varianten, die sich nach Vorhandensein eines weiteren Betriebssystems unterscheiden, aber beide die Voraussetzungen von Popek und Goldberg erfüllen.
Typ 1 Hypervisoren werden ohne ein Betriebssystem direkt auf der Hardware installiert und haben deshalb auch die Bezeichnung \textit{Bare-Metal} (dt. nacktes Metall). Bei dieser Implementierung kommuniziert der Hypervisor direkt mit den Ressourcen, ohne dafür ein zwischengelagertes Betriebssystem zu benötigen. Neben Bare-Metal werden diese Art von Hypervisoren auch als \textit{native} Hypervisoren bezeichnet. Da durch die direkte Vermittlung der I/O Anfragen der virtuellen Maschinen eine effiziente Performance des Gesamtsystems geliefert werden kann, kommen Typ-1-Hypervisoren oftmals bei Servern zum Einsatz. Beispiele für native Hypervisoren sind VMware ESXi, Citrix Xen oder Microsoft Hyper-V. \cite[S.~44]{Portnoy2012}\medskip\\
Die zweite Variante der Hypervisoren wird unter dem Namen Typ-2-Hypervisoren zusammengefasst. Der wesentliche Unterschied zum Typ-1-Hypervisor ist die Ausführung als eigenständige Applikation. Ein Typ-2-Hypervisor läuft als Programm in einem traditionellen Betriebssystem und nutzt dessen Hardwaretreiber als Zugriff zu den phyischen Ressourcen. Klar erkennbar ist an dieser Stelle, dass bei I/O Anforderungen der virtuellen Maschine zusätzliche Schritte im Ablauf hinzukommen, da der Hypervisor die Aufgabe selbst erst an das Betriebssystem deligieren muss. Während bei der ersten Variante der Zugriff direkt möglich ist, erfordert der Typ-2-Hypervisor mit dem Betriebssystem eine zusätzliche Verwaltungsschicht, welche ebenfalls verwaltet werden muss. Weil Typ-2-Hypervisoren auf einem Client installiert sein müssen, werden sie auch als \textit{hosted hypervisor} (dt. gehosteter Hypervisor) bezeichnet. Die bekanntesten Beispiele für gehostete Hypervisoren sind VMware Workstation und Oracle VirtualBox. \cite[S.~45]{Portnoy2012}
\begin{figure}[H]
    \centering
    \subfigure[Server basierte Virtualisierung (Typ 1 Nativ)]{\label{SchemaVirt:Nativ}\includegraphics[width=0.35\textwidth]{Images/a7d9b1cf-cfce-4ea9-9d12-8ea0650e51b2.jpg}}
    \hspace{0.15\textwidth}
    \subfigure[Client basierte Virtualisierung (Typ 2 Hosted)]{\label{SchemaVirt:Hosted}\includegraphics[width=0.4\textwidth]{Images/414218d2-6c27-4908-a801-941a44a03eb4.jpg}}
    \caption[Schema Virtualisierungsvarianten]{Schema Virtualisierungsvarianten \cite[S.~13]{SiemensIndustryOnlineSupport2018}}
    \label{SchemaVirt}
\end{figure}
In \autoref{SchemaVirt} werden die beiden Konzepte der Virtualisierungen gegenübergestellt. Während beim nativen Hypervisor in Abbildung \autoref{SchemaVirt:Nativ} die virtuellen Maschinen direkt vom Hypervisor vermittelt werden, liegt beim gehosteten Hypervisor in Abbildung \autoref{SchemaVirt:Hosted} das Betriebssystem zusätzlich dazwischen. Beide Varianten vereint, dass für die virtuellen Maschinen eine isolierte Umgebung zur Verfügung gestellt wird, in denen sie normal betrieben werden können.
\subsection{Virtuelle Maschine}
\begin{quote}\textit{\glqq Eine \acrfull{vm} ist ein nachgebildeter Rechner, der in einer isolierten Umgebung auf einem realen System l{\"a}uft.\grqq{}}~\cite[S.~197]{Baun2009}\end{quote}
Dieser nachgebildete Rechner agiert wie ein vollwertiger Computer und besitzt auch eigene Komponenten, wie CPU, Hauptspeicher und Festplatten. Die Betriebssystemsoftware, die auf der virtuellen Maschine betrieben wird, merkt im Idealfall nicht, dass die scheinbar realen Komponenten emuliert sind. Möglich macht dies der zwischengelagerte Hypervisor, der alle Anforderungen des Gastbetriebssystems abfängt und auf die reale Hardware umsetzt. Die virtuelle Maschine wird in einer Virtualisierungsumgebung auch als Gastsystem bezeichnet, da sie nicht an die Hardware direkt gebunden ist, sondern mittels standardisierter Templates auch in anderen Umgebungen ausgeführt werden könnte. \cite[S.~197]{Baun2009}\medskip\\Diese Templates dienen dazu, eine vorkonfigurierte, bereits geladene virtuelle Maschine als Kopie zu erstellen. Das Template kann in der Virtualisierungsumgebung nicht ausgeführt werden, dazu muss es wieder in eine virtuelle Maschine umgewandelt werden. Die aus einem Template erstellte virtuelle Maschine muss nicht von Grund auf neu konfiguriert werden, sondern benötigt lediglich eine neue Identität (IP-Adresse, Name), um nicht als Doppelgänger der ursprünglichen Konfiguration betrieben zu werden. Mit dieser Vorgehensweise kann eine gesamte virtuelle Maschine inkl. der installierten Applikationen mittels einer einzelnen Datei ausgeliefert werden. Virtuelle Maschinen, die in ein Template umgewandelt werden, existieren danach nicht mehr als ausführbare Maschine. Um ein Template einer laufenden Maschine zu erstellen, sollte deshalb vorher ein Klon dieser Maschine erstellt werden. \cite[S.~71]{Portnoy2012}\medskip\\
Um möglichst plattform- und anbieterunabhängig virtuelle Maschinen bereitstellen zu können, wurde ein Dateiformat für den Austausch entwickelt. Das \acrfull{ovf} bündelt die virtuelle Maschine in nur eine Datei und ermöglicht somit das leichte Transportieren zwischen Virtualisierungsumgebungen. \cite[S.~74]{Portnoy2012}\medskip\\
Neben den Templates existieren auch noch Snapshots (dt. Schnappschüsse) einer virtuellen Maschine, die den Zustand dieser zu einem bestimmten Zeitpunkt darstellen. Es werden sowohl die Daten als auch die Hardwarekonfiguration der virtuellen Maschine aufbewahrt. Sobald ein Snapshot gespeichert wird, werden alle Änderungen an der virtuelle Maschine nicht mehr auf der originalen Disk, sondern auf einer sog. Delta- oder Childdisk gespeichert. Wenn z.B. eine Applikation durch das Durchführen eines Updates nicht mehr korrekt ausgeführt wird und ein Snapshot \glqq\textit{vor-Update}\grqq{} existiert, so kann problemlos der vorherige Zustand wiederhergestellt werden. \cite[S.~73]{Portnoy2012}\medskip\\
Virtuelle Maschinen sind also isolierte Rechner mit normalen Betriebssystemen, die sich wie ihre physischen Gegenstücke verhalten, dabei aber in der Virtualisierungsumgebung besser verwaltet und administriert werden können. Alles, was von einer realen Maschine erwartet werden kann, wird ebenso von der virtuellen Maschine bereitgestellt. Zusätzlich sind sie dabei schneller einsatzbereit und können schneller zwischen Systemen migriert werden. \cite[S.~75]{Portnoy2012}
%\section{Überblick Virtualisierungsanbieter}
\section{Virtualisierung mit VMware Komponenten}
Die serverbasierte Virtualisierung von VMware wird unter dem Oberbegriff \textit{vSphere} zusammengefasst, welche eine Produktlinie mit einer Vielzahl von unterschiedlichen Produkten der Virtualisierung ist. Während von VMware die essentiellen Komponenten wie Hypervisor und Managementsoftware bereitgestellt werden, greift die vSphere aber auch auf Komponenten von anderen Anbietern zurück. \cite[S.~43]{Wohrmann2018}\medskip\\
Als physischer Server, der seine Hardware in Form von \acrshort{cpu}, Hauptspeicher, Netzwerkkarten und Festplattenspeicher für die Virtualisierungsumgebung bereitstellt, kann z.B. auf Server der Firma HP zurückgegriffen werden. Beispielsweise eignet sich die \textit{ProLiant DL300}-Reihe optimal als Virtualisierungshost für die vSphere. Für den
\begin{wrapfigure}[8]{ht}[0cm]{10cm}
    \centering
    \includegraphics[width=0.7\textwidth]{Abbildungen/hphost.png}
    \caption[Virtualisierungshost Beispielabbildung]{Virtualisierungshost Beispielabbildung \footnotemark} 
    \label{fig:Beispielhost}
\end{wrapfigure}
\footnotetext{Quelle: HPE, ProLiant DL300 Server; URL: \url{https://buy.hpe.com/at/de/servers/proliant-dl-servers/proliant-dl300-servers/proliant-dl380-server/hpe-proliant-dl380-gen10-server/p/1010026818}; abgerufen am 19.05.2021}Einsatz in der vSphere benötigen die Hosts einen 64-Bit-x86-Prozessor, der mindestenes zwei CPU-Kerne mitbringt. Der Minimalbedarf an Arbeitsspeicher beträgt 4 \acrshort{gb}, wobei für das Nutzen aller Funktionen mindestens 8 GB empfohlen werden.~\cite[S.~54]{Wohrmann2018}\medskip\\
Wie in \autoref{fig:Beispielhost} auf der rechten Seite des Hosts erkennbar, sollte der physische Server auch ausreichend Platz für Festplatten mitbringen. Auf der Rückseite des Hosts befindet sich eine Vielzahl an Netzwerkports, die eine Verbindung zu unterschiedlichen Netzwerken ermöglichen. Die hier dargestellte Hostausführung ist für den Rackeinbau gedacht, wofür ein Schienensystem inkl. Leitungsführung für den unkomplizierten Wartungszugriff benötigt wird.\medskip\\
Die vSphere benötigt also mindestens einen der hier vorgestellten Virtualisierungshosts oder vergleichbare Hardware, die die Systemvoraussetzungen erfüllt. Auf dieser Hardware wird der Hypervisor \textit{ESXi} installiert, der als Typ-1-Hypervisor das Management der Ressourcen übernimmt. Unter dem Namen \textit{vSphere Hypervisor} ist ESXi auch als freie Variante beispielsweise zu Lern- und Schulungszwecken einsetzbar. In der freien Version wird der Hypervisor mit einigen Performancebeschränkungen ausgeliefert, die aber für das grundlegende Verständnis einer Virtualisierungsumgebung keinen Nachteil haben. Virtuelle Maschinen können, wie im kostenpflichtigen Modell auch, ganz normal betrieben werden, jedoch ist ein Management über den vCenter Server in der freien Variante nicht möglich.~\cite[S.~42]{Wohrmann2018}\medskip\\
Die lizenzierte Variante von ESXi wird immer dann benötigt, wenn das volle Potential der vSphere mittels der Managementsoftware vCenter Server ausgenutzt werden soll. Dazu zählt unter anderem das Verschieben von laufenden virtuellen Maschinen mittels \textit{vMotion} oder das Erkennen von Ausfällen mit \textit{Fault Tolerance} oder \textit{High Availability}. Die vSphere ermöglicht dem Kunden, seine Virtualisierungsumgebung so effizient wie möglich zu betreiben, dabei eine hohe Ausfallsicherheit zu erreichen und dynamisch auf Lastverschiebungen eingehen zu können.~\cite[S.~46]{Wohrmann2018}\medskip\\
Mit der Managementsoftware vCenter Server stellt die Firma VMware ihren Kunden einen zentralen Zugangspunkt zu deren Virtualisierungsumgebungen bereit. Ausgeführt ist diese Software als virtuelle Maschine, die unter dem Namen \textit{\acrlong{vcsa}} selbst auf einem der Hosts installiert ist und hauptsächlich als Datenbank genutzt wird. Mithilfe spezieller Software-Agenten, die auf jedem zu überwachenden Host bzw. Server installiert sein müssen, ermöglicht vCenter Server die Überwachung, Steuerung und Administration der gesamten vSphere-Umgebung. Agenten und Server nutzen für die bidirektionale Kommunikation Webservices, wobei sie sich am Industriestandard \acrfull{cim} orientieren. Als plattformunabhängiger Standard ermöglicht \acrshort{cim} das anbieterunabhängige Management der IT-Infrastruktur in vCenter Server. ~\cite[S.~415]{Bengel2015}\medskip\\
Obwohl sich ein Anwender mit den virtuellen Maschinen eines Hosts direkt im Browser verbinden könnte, wird meist der Weg über vCenter Server gewählt. Der Grund dafür ist die nutzerfreundliche Implementierung der Funktionen in vCenter Server. Der Zugangspunkt zur Managementsoftware ist der vSphere Client, welcher als HTML5 basierte Webseite ein modernes und reaktionsschnelles Auftreten im Browser aufweist. Mit der Anmeldung in diesem Client wird durch die Option \textit{vCenter Single Sign On} eine weitere Authentifizierung auf anderen Instanzen automatisch übernommen. Der Anwender konzentriert sich also völlig auf die Administration der virtuellen Umgebung, anstatt den aktuellen Arbeitsprozess durch wiederholte Überprüfung der Anmeldedaten immer wieder zu unterbrechen. Weiterhin ermöglicht vCenter Server eine sofortige Bestandssuche im gesamten Virtualisierungssystem, um z.B bei Warnungen direkt zum Ursprung dieser zu gelangen und schnell eventuelle Fehler zu vermeiden. Neben den Warnungen können auch normale Benachrichtigungen über definierte Ereignisse generiert werden, um z.B. automatische Abläufe zu starten oder dem Administrator wichtige Details mitzuteilen. Die in vCenter Server integrierten Werkzeuge zur Migration, Wiederherstellung und Backuperstellung ermöglichen im Zusammenspiel mit dafür vorgesehenen Scheduler eine planbare und definierte Administration der gesamten Virtualisierungsumgebung.~\cite[S.~2]{VMware2018}\medskip\\
Die Dynamik im Ressourcenmanagement, welche durch vCenter Server implementiert wird, ermöglicht eine optimale Ausnutzung der verfügbaren Hardware. Auch im laufenden Betrieb können die physischen Ressourcen eines Servers dynamisch den virtuellen Maschinen zugeordnet werden.
Ein Administrator kann dafür vordefinierte Regeln festlegen, wonach die Ressourcen intelligent auf die virtuellen Maschinen verteilt werden und z.B. bei höchster Auslastung weitere Ressourcen in Anspruch nehmen. Somit passt sich die Virtualisierungsumgebung automatisch den geschäftlichen Anforderungen und den sich ändernden Prioritäten an, ohne einen manuellen Lastausgleich durchführen zu müssen \cite[S.~3]{VMware2018}.
Die Auslastungsgrenze des Gesamtsystems ist also nicht auf die statische Ressourcenzuweisung einer virtuellen Maschine begrenzt, sondern spiegelt die maximale Performance des verwendeten Hosts unter Beachtung der konfigurierten Regeln wider.

\chapter{Betriebssystem Windows Server}
Unter Windows Server versteht man das Betriebssystem der Firma Microsoft, welches zur Nutzung auf physischen oder virtuellen Servern gedacht ist. Windows Server ist die funktionale Version des allgemein bekannten Betriebssystem Windows. Beide Betriebssysteme vereint eine gemeinsame Quelltextbasis, wodurch neue Versionen beider Systeme immer im ähnlichen zeitlichen Rahmen erscheinen. Die zum Zeitpunkt dieser Anfertigung aktuelle Version ist Windows Server 2019, welches auf Windows 10 basiert. Die Besonderheit von Windows Server ist dabei, dass die Funktionalität und Verfügbarkeit des Betriebssystems im Vordergrund steht, wodurch optionale Funktionen des anwenderfreundlichen Windows entfallen. Windows Server ist dafür ausgelegt, in einem geschäftlichen Rahmen genutzt, administriert und verwaltet zu werden und bietet deshalb auch Virtualisierungsmöglichkeiten an. Dafür stehen dem Administrator verschiedene Anwendungen zur Verfügung, die hier im Überblick vorgestellt werden sollen. \cite{Hagel2021}
\section{Server-Manager}\label{sec:servermanager}
Sobald mehrere Windows Server in der IT-Umgebung vorhanden sind, müssen diese zwangsläufig verwaltet werden. Der Server Manager in Windows Server bietet dem Administrator dafür die Möglichkeit, alle verbundenen Server flexibel zu administrieren. Die Anwendung kann dabei auf einer einzelnen Station ausgeführt werden und remote auf alle vorhandenen Server zugreifen, um die Serverrollen festzulegen oder sie mittels \textit{Best Practices Analyzer} zu überprüfen~\cite[S.~20 ff.]{2014}.
Dabei ist es nicht zwingend notwendig, dass phyischer Zugriff auf den Server möglich oder eine \acrlong{rdp}-Sitzung bereits angelegt ist. In der Verwaltungskonsole werden Ereignis- und Leistungsprotokolldaten aller konfigurierten Server im Netzwerk zusammengetragen und dem Administrator anschaulich dargestellt. Weiterhin werden den Servern zugeordnete Aufgaben und Ereignisse auf dem Übersichtsplan angezeigt und bei Bedarf eine Benachrichtigung an den Administrator ausgelöst. Besonders bei realen Umgebungen, in denen die Windows Server nicht virtualsiert sind, ist die Erfassung der Leistungsdaten und Ereignisse im Server-Manager sehr hilfreich. \cite{Microsoft2017}
\section{Active Directory}\label{sec:ad}
Zu einem Windows Server haben üblicherweise mehrere Benutzer Zugang. Um die Rechte dieser Benutzer zu verwalten und den Benutzerzugang zu authentifizieren, benötigt der Administrator das Active Directory, welches alle Benutzer als Objekte einer Datenbank behandelt. Damit ist das Gruppieren von Benutzern möglich, um z.B. deren Zugang zu Geräten wie Druckern oder Servern zu verwalten oder die Freigabe von Benutzerrechten zu administrieren. \cite[S.~30 ff.]{2014}
\section{Windows Update Server}\label{sec:wsus}
%WSUS --> späterer Verweis auf PCS 7 Updates\\\cite{White2004}
Die Funktionsweise der Windows Updates basiert auf dem Zusammenspiel vom Windows Update-Client und dem Windows Update-Server. Der Client ermittelt notwendige Updates und installiert diese. Der Bezugspunkt, von dem der Client die Windows Updates bezieht, ist der Windows Update-Server, der normalerweise online von Microsoft betrieben wird. Wenn kein Onlinezugang möglich ist, oder der Updateprozess innerhalb des Unternehmens verwaltet und gesteuert werden soll, empfiehlt sich die Installation eines unternehmensinternen Servers, der dann die \acrfull{wsus} betreut. Dieser Server steuert die Verfügbarkeit der Updates und lädt sie erst herunter, wenn sie eine Freigabe erhalten haben. Updates mit erfolgreicher Freigabe werden anschließend durch den Update-Client auf den verwalteten Rechnern installiert. \cite[S.~235 f.]{Voges2019}
\newpage
\section{Gruppenrichtlinien}\label{sec:GPO}
\begin{quote} \textit{\glqq Gruppenrichtlinien sind Benutzer- oder Computereinstellungen, die zentral konfiguriert und abgelegt sind und auf einen oder eine Gruppe von Computern oder Benutzern angewendet werden k{\"o}nnen.\grqq{}}~\cite[S.~1]{Voges2019}\end{quote}
Gruppenrichtlinien sind in Sammlungen zusammengefasst, die als \acrfull{gpo} bezeichnet werden.
Sie dienen dazu, Software zu verteilen und Sicherheitseinstellungen vorzunehmen, Funktionen oder Dienste zu konfigurieren und dem Benutzer des Computers eine bestimmte Oberfläche bereitzustellen. Sobald die Computer zentral mittles Gruppenrichtlinie verwaltet werden, hat der Benutzer keinen Einfluss auf die parametrierten Eigenschaften mehr, denn diese werden vorgegeben und teilweise auch erzwungen. \cite[S.~1]{Voges2019}\medskip\\
Um den Prozess der Computerverwaltung noch effizienter zu gestalten, kann auf PowerShell zurückgegriffen werden. Mit bestimmten Erweiterungen zum Umgang mit Gruppenrichtlinien lassen sich mit den PowerShell-Befehlen viele Verwaltungsaufgaben, wie z.B. das Sichern von Gruppenrichtlinien, automatisieren \cite[S.~517]{Voges2019}. Nähere Beschreibungen zum Umgang mit der PowerShell im Hinblick auf die Automatisierung von Systemen finden sich im \myRef{PowerShell}.
\section{Automatisierung durch Verwendung von Skripten}
Die älteste Form der Automatisierung ist die Programmierung von Stapeln (engl. Batch). Sobald eine Textdatei auf Windows Betriebssytemen die Endung .bat erhält, wird sie zu einer ausführbaren Stapelverarbeitungsdatei, die von der Eingabeaufforderung cmd.exe gestartet werden kann. Damit können einfache Systemvorgänge, wie z.B. das Kopieren oder Löschen von Verzeichnissen, automatisiert werden. Ein Administrator stößt mit komplexeren Konfigurations- und Verwaltungsaufgaben eines Rechners aber schnell an die Grenzen des Funktionsumfangs der Stapelverarbeitung. In den 1990er Jahren veröffentlichte Microsoft mit dem \acrfull{wsh} die langersehnte Alternative zur Batch-Programmierung, welche aufgrund der Active-Scripting-Architektur das Skripten in vielen Microsoft Produkten unterstützt~\cite[S.~1]{Schwichtenberg2016}.
Der \acrlong{wsh} gehört seit Windows 98 zum Standardinstallationsumfang der Windows Betriebssysteme und wurde dementsprechend auch ständig weiterentwickelt. Im aktuellen Windows 10 ist der \acrlong{wsh} in der Version 5.8 enthalten~\cite[S.~2]{Schwichtenberg2016}. Im Gegensatz zu anderen Entwicklungsumgebungen enthält der \acrlong{wsh} keine eigene Programmiersprache, sondern ist für die Zusammenarbeit mit verschiedenen Programmiersprachen ausgelegt. Standardmäßig ist die Sprache \acrfull{vbs} von Microsoft enthalten, es können aber auch Sprachen wie Python, Pearl oder Ruby von anderen Herstellern integriert werden. Der Funktionsumfang ist damit nicht auf eine Version oder Sprache begrenzt, sondern kann durch Hinzufügen anderer Programmiersprachen erweitert werden~\cite[S.~4]{Schwichtenberg2016}.
Eine andere Möglichkeit zur Automatisierung, die ebenfalls im Standardinstallationsumfang der Windows Betriebssysteme enthalten ist, ist die PowerShell. Als funktionaler Nachfolger der Eingabeaufforderung cmd.exe beinhaltet die PowerShell alle bekannten Funktionen des Vorgängers und erweitert dessen Funktionalität deutlich. PowerShell steht einem versierten Administrator als multifunktionales Konfigurationswerkzeug mit hilfreichen Befehlen und einer Kombination aus Konsole und Entwicklungsumgebung zur Verfügung ~\cite[S.~399]{Schwichtenberg2016}. Detaillierte Ausführungen zur Funktionsweise sind im \myRef{PowerShell} zu finden.
\begin{comment}
älteste Form Batch Programmierung (Stapelverarbeitungsdatei) wird vom Kommandozeileninterpreter ausgeführt. Meist in der Eingabeaufforderung cmd.exe realisiert und ausgeführt. Nachteil daran: sehr kompliziert und Außerdem im Funktionsumfang nicht mächtig genug für Systemadministration. Entstehende Marktlücke durch fehlendes Durchsetzungsvermögen von kleinen unbekannten Drittanbietern. IN 90er Jahren durch WSH Windows Scripting Host diese Marktlücke geschlossen


windows scripting host

visual basic scripte\\
batch\\
cmd\\
powershell\\
\end{comment}



\chapter{PCS 7 als Zielsystem}
\section{Überblick}
\acrshort{pcs} 7 ist der Produktname des Prozessleitsystems der Siemens AG und steht für \textit{\acrlong{pcs}}. Die vielfältigen und individuellen Lösungen des Leitsystems bieten dem Kunden eine optimale Schnittstelle zum Prozess und garantieren eine ideale Wertschöpfungskette.
\vspace{-3.0mm}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{Images/03a59b61-4b4a-46d9-b4e7-c2c879dad688.jpg}\caption[Übersicht Totally Integrated Automation (TIA)]{Übersicht Totally Integrated Automation (TIA) \cite[S.~2]{SiemensAG2017}\label{fig:PCS7Überblick}}
\end{figure}
\vspace{-3.0mm}
Überzeugen kann PCS 7 vor allem durch perfekt aufeinander abgestimmte Produkte, die im sog. \acrfull{tia} nahtlos interagieren. Mit PCS 7 wird die industrielle Automatisierung auf allen Hierarchieebenen ermöglicht. Von der Unternehmensleitebene bis hin zur Feldebene wird damit eine kundenspezifische Automatisierung realisiert. Zum Einsatz kommt das Prozessleitsystem vor allem bei Kunden der Branchen Fertigungs- und Prozessindustrie. \cite[S.~4]{SiemensAG2017}\medskip\\
\autoref{fig:PCS7Überblick} zeigt schematisch die möglichen Einsatzgebiete und Schnittstellen des Prozessleitsystems, das für die gängigen Anwendungen der Prozessautomatisierung bereits vorgefertigte Lösungen anbietet. Als Beispiel dient das Wiegen und Dosieren in der Feldebene, welches als Vorgang in vielen Prozessen benötigt wird. PCS 7 bietet dafür vorgefertigte Module, die nur noch mit den passenden Komponenten konfiguriert werden müssen und anschließend einsatzbereit sind.\medskip\\
Die Vielfältigkeit des Produkts PCS 7 reicht von der Projektierung der Anlage über den täglichen Betrieb inkl. Sicherheitsfunktionen bis hin zur Instandhaltungsplanung. Die Skalierbarkeit der Lösung ist einer der Gründe, warum PCS 7 in so vielen Anwendungsbereichen eingesetzt wird. Vom kleinen Laborsystem bis zum Anlagenverbund mit über 200.000 \acrshort{plt}-Stellen bietet PCS 7 die Möglichkeit zum anlagenweiten, effizienten Engineering.~\cite[S.~9]{SiemensAG}
\section{Bestandteile PCS 7}
Um ein Verständnis dafür zu erlangen, wie das Zusammenspiel der Komponenten in PCS 7 funktioniert, müssen die wichtigsten Komponenten kurz vorgestellt werden.\medskip\\
Bei der Erstellung eines PCS 7-Projekts dient der \textit{SIMATIC Manager} als zentrale Applikation, von der das gesamte Projekt aufgebaut wird. Darin sind verschiedene Editoren enthalten, mit denen man die essentiellen Bausteine, wie z.B. \acrfull{cfc} und \acrfull{sfc}, zur Projektierung von Ablaufsteuerungen, sowie die Hardwarekonfiguration der Anlage erstellt und bearbeitet \cite[S.~20]{SiemensAG2018b}. Diese Projektierung wird typischerweise auf einer \textit{\acrfull{es}} ausgeführt, welche sowohl im Industrie- als auch im Bürobereich eingesetzt werden kann \cite[S.~11]{SiemensAG2017}.
Die Schnittstelle des Prozesses zum Anlagenbediener nimmt die \textit{\acrfull{os}} ein, auf der zuvor projektierte Prozessbilder angezeigt werden. Der Anlagenbediener nutzt diese Station zum Bedienen und Beobachten des Prozesses. Die dafür erforderlichen Daten liest die OS aus dem \textit{\acrfull{as}} aus, welches das direkte Steuern und Regeln des Prozesses mithilfe von  IO- Baugruppen übernimmt \cite[S.~145]{SiemensAG2018b}. \autoref{fig:MinimalKonfigPCS7} zeigt die 
\begin{wrapfigure}[13]{ht}[0cm]{7.7cm}
    \includegraphics[width=0.5\textwidth]{Images/54bcf1f1-ccc4-4fa2-8db5-5daf83ff8efe.jpg}\caption[Minimalkonfiguration PCS 7]{Minimalkonfiguration PCS 7 \cite[S.~11]{SiemensAG2020}}
    \label{fig:MinimalKonfigPCS7}
    \centering
\end{wrapfigure}
Minimalkonfiguration einer PCS 7-Anlage, wobei die OS und ES hier auf einer einzelnen realen Maschine ausgeführt werden. Als Automatisierungssystem dient eine S7 der 400er Reihe in Zusammenspiel mit einer dezentralen Komponente, welche hier eine ET200 ist. Beide Systeme stammen vom Hersteller Siemens und integrieren sich somit problemlos in die Kleinstanlage. Für die Kommunikation der Komponenten untereinander werden je nach Hierarchieebene verschiedene Bussysteme, wie z.B. Industrial-Ethernet oder Profibus-DP, benötigt. Die Komplexität dieser Konfiguration wird schnell erhöht, wenn neben der Anlage auch die Funktionsansprüche an das Leitsystem wachsen. Eine Erweiterung der Anlage zieht meist auch die Verwendung von neuen PCS 7-Stationen mit sich, die jeweils für separate Anlagenteile verwendet werden. Größer werdende Anlagen haben aber neben mehr Stationen meist auch den Anspruch an komplexere Funktionen, wie z.B. die Redundanz oder Archivierung. Beides sind Beispiele für Erweiterungsmöglichkeiten des Leitsystems, die zusätzliche Hardware erfordern. 
\vspace{-4.0mm}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Images/d14ad340-5f67-4c7d-9cca-1f28fe5ce178.jpg}\caption[Schema zur PCS 7-Struktur in unterschiedlichen Anlagengrößen]{Schema zur PCS 7-Struktur in unterschiedlichen Anlagengrößen \cite[S.~8]{SiemensAG2020}}
    \label{fig:StrukturAnlagenGrößePCS}
\end{figure}
\vspace{-3.0mm}
Zusätzliche Hardware bedeutet gleichzeitig auch, dass der Platz- und Energiebedarf der PCS 7-Komponenten deutlich steigt. Wie man in \autoref{fig:StrukturAnlagenGrößePCS} erkennt, bedeutet eine Vergrößerung der Anlagenstruktur vom Labor über das Technikum bis zum Anlagenverbund auch eine Vielzahl neuer PCS 7-Komponenten, wie Stationen oder Servern. Für die meisten Komponenten werden Industrie-PC benötigt, um Serverbetriebssysteme wie Windows Server für PCS 7 zu betreiben. Diese sind mit dem Betriebssystem meist nicht optimal ausgelastet und somit wirtschaftlich überdimensioniert. Um die Wirtschaftlichkeit einer Anlage zu steigern und dabei minimalen Ressourcenaufwand zu haben, werden die PCS 7-Komponenten ab einer gewissen Anlagengröße virtualisiert. Die Art und Weise der Virtualisierung der PCS 7-Komponenten wird im nächsten Abschnitt genauer beschrieben.

\section{Virtualisierung}
Wie im \myRef{chap:Virt} bereits beschrieben, ist das Ziel der Virtualisierung die optimale Ausnutzung der zugrunde liegenden Hardware und damit das Optimieren des Platz- und Energiebedarfs der gesamten Anlage. Die Virtualisierung einer PCS 7-Anlage hat, wie jedes andere Virtualisierungsprinzip auch, die Steigerung der Wirtschaftlichkeit als Ziel. Vor allem über den langen Lebenszyklus einer Automatisierungsanlage von nicht selten über 20 Jahren bedeutet jede noch so kleine Ressourcenoptimierung der Systemstruktur das Einsparen von vermeidbaren Investitionen in der Zukunft. Bezogen auf das System einer PCS 7-Anlage betrifft die Virtualisierung vor allem die Operator- und Engineeringstationen. Bei der klassischen Ausführung von PCS 7 müssen beide Stationstypen mit einem eigenen realen System, meist einem Industrie-PC, ausgestattet sein, um die Anforderungen von PCS 7 zu erfüllen. Da es jedoch nicht empfohlen ist, einen solchen Industrie-PC dauerhaft an seiner Leistungsgrenze zu betreiben, bleibt ein Restpotential in der vorhandenen Hardware bestehen. Die Stationen sind dadurch nicht zu 100\% ausgelastet, obwohl sie dauerhaft Energie und Platz benötigen.\medskip\\
Die Virtualisierung der Komponenten soll dieser Ineffizienz entgegenwirken, indem sie die Stationen als virtuelle Maschinen ausführt. Genutzt wird dafür die serverbasierte Virtualisierung unter Verwendung von Softwarelösungen des Herstellers VMware. Die Anlage wird je nach Anlagengröße und Redundanzbedarf mit einem oder mehreren Servern ausgestattet, die als reales Hostsystem für eine Virtualisierungsumgebung dienen. In dieser Virtualisierungsumgebung werden die Operator- und Engineeringstationen als virtuelle Maschinen betrieben. Die leistungsstarken realen Maschinen für OS und ES entfallen und werden durch sog. ThinClients ersetzt. Diese haben als 
\begin{wrapfigure}[11]{ht}[0cm]{5cm}
    \includegraphics[width=0.3\textwidth]{Abbildungen/thinclient.jpg}\caption[Beispielbild ThinClient]{Beispielbild ThinClient\protect\footnotemark}
    \label{fig:ThinClient}
    \centering
\end{wrapfigure}
\footnotetext{Quelle: HP Support, URL=\url{https://support.hp.com/doc-images/194/c04356309.jpg}, abgerufen am 29.06.2021}einzige Aufgabe, über das Anlagennetzwerk mithile einer \acrfull{rdp} Sitzung eine Verbindung zur virtuellen Maschine herzustellen und diese lokal anzuzeigen. Für den Anlagenbediener ist keine Veränderung in der gewohnten Bedien- und Beobachtungsfunktionalität spürbar, obwohl die Rechenleistung der Operator Station vollständig verlagert wurde.  Wie in \autoref{fig:ThinClient} zu erkennen, sind die verwendeten ThinClients deutlich kleiner als herkömmliche Industrie-PC. Da sie abgesehen von der Netzwerkfähigkeit und einer einfachen Grafikkarte praktisch keine spezielle Rechenleistung benötigen, werden sie sehr leistungs- und energieeffizient ausgeführt. Im Vergleich zum Betrieb eines Industrie-PC sind sie dadurch kostengünstiger, vor allem wenn man die Anschaffungskosten und den Platz- und Energiebedarf der Geräte vergleicht.~\cite[S.~74]{SiemensAG2017}\medskip\\Wie oben bereits beschrieben, entfallen die realen Maschinen für die Operator- und Engineeringstationen und werden durch die Kombination aus ThinClients und virtueller Maschine ersetzt. Um die virtuellen Maschinen mit ihren Gastbetriebssystemen betreiben zu können, muss ein Server, welcher auch als Hostsystem bezeichnet wird, bereitgestellt werden. Die PCS 7-Virtualisierung basiert auf Komponenten und Lösungen der Firma VMware, die für diese Art der serverbasierten Virtualisierung auf Hosts der Firma HP zurückgreift. Diese Hosts werden mit dem Serverbetriebssystem ESXi betrieben, welches als nativer Hypervisor die Ausführung der virtuellen Maschinen ermöglicht. Die nachfolgende \autoref{fig:virtuellerAufbau} zeigt schematisch den Unterschied zwischen realem und virtuellen Aufbau einer PCS 7-Konfiguration.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Images/a27c54c2-945d-4fea-97c6-d2213378c1ee.jpg}\caption[Schema zum physikalischen und virtuellen PCS 7-Aufbau]{Schema zum physikalischen und virtuellen PCS 7-Aufbau \cite[S.~10]{SiemensIndustryOnlineSupport2018}}
    \label{fig:virtuellerAufbau}
\end{figure}
Die hier dargestellte Anlagengröße eignet sich aufgrund der geringen Anzahl an Stationen nur als theoretisches Schema für eine Virtualisierung. Die Anschaffungskosten für den Host könnten nur bei sehr langer Betriebsdauer durch die Energieeinsparungen und den Wegfall der realen Stationen amortisiert werden. Bei langen Anlagenbetriebsdauern von mehreren Jahrzehnten ist von einem Systemupgrade innerhalb dieses Zeitraums auszugehen, um wirtschaftlich die Kundeninteressen abbilden zu können. Anders als bei dem hier dargestellten System mit nur vier Stationen ist die Kosteneinsparung bei größeren PCS 7-Installationen mit Virtualisierung deutlich höher, weil eine größere Anzahl an realen Maschinen durch die Kombination aus Thin-Client und virtueller Maschine ersetzt wird und durch die Serverstruktur glechzeitig Redundanz- und Sicherheitsansprüche der Anlage abgedeckt werden.
\chapter{Powershell}\label{PowerShell}
\begin{quote}\textit{\glqq PowerShell ist ein plattform{\"u}bergreifendes Framework zur Aufgabenautomatisierung und Konfigurationsverwaltung, das aus einer Befehlszeilenshell und einer Skriptsprache besteht.\grqq{}}~\cite[S. 1]{Microsoft2021}\end{quote}\vspace{-3mm}
\section{Historie}
Eine vorhandene Systemumgebung mit minimalem Zeitaufwand zu verwalten und sich wiederholende Aufgaben zu automatisieren, ist seit Windows DOS die Lebensaufgabe eines jeden Administrators. Wer sich in der Welt des objektorientierten Programmierens allerdings nicht sehr fundiert auskannte, stieß beim Active Scripting in der Vergangenheit schnell an seine Grenzen. Die vielen Ausnahmen und Ungereimtheiten des Windows Scripting Hosts standen einer unkomplizierten Anwendungsentwicklung zusätzlich im Weg. Im Jahre 2002 veröffentlichte Microsoft das Framework .NET, wodurch die Spekulationen für einen Windows Scripting Host auf .NET Basis vorangetrieben wurden. 
Dieser Entwicklung steuerte Microsoft jedoch entgegen, da man dem Anwender nicht noch mehr Wissen über objenktorientierte Programmierung abverlangen wollte und sich die Shells der UNIX-Welt sehr großer Beliebtheit erfreuten. Microsoft entschloss sich deshalb, das Konzept des Pipelinings aus den UNIX-Shells mit dem .NET Framework zu kombinieren. Man wollte das Beste aus beiden Welten zusammenführen und somit dem Anwender eine noch einfachere Shell auf Basis des .NET Frameworks bereitstellen.
\cite[S.~23]{HolgerSchwichtenberg2018}\vspace{-3mm}
\begin{quote}\textit{\glqq Nach den Zwischenstufen {\glqq}Microsoft Shell (MSH){\grqq} und {\glqq}Microsoft Command Shell{\grqq} tr{\"a}gt die neue Skriptumgebung seit Mai 2006 den Namen {\glqq}\textbf{Windows PowerShell}{\grqq}.\grqq{}}~\cite[S.~23]{HolgerSchwichtenberg2018}\end{quote}
Am 06.11.2006 ist die erste Version der PowerShell zusammen mit Windows Vista erschienen. PowerShell 1.0 war in diesem Betriebssystem allerdings nicht enthalten, sondern musste nachinstalliert werden. In den folgenden Jahren veröffentlichte Microsoft die neuen PowerShell Versionen jeweils zeitgleich und bereits vorinstalliert mit den Betriebssystemen Windows 7, 8, 8.1 und 10, sowie Windows Server 2008 R2, 2012, 2012 R2 und 2019. Am 20.01.2018 wurde die erste Windows-unabhängige Version der PowerShell mit dem Namen PowerShell Core veröffentlicht, die auch auf macOS und linux-basierten Systemen ausgeführt werden konnte. \cite[S.~23 ff.]{HolgerSchwichtenberg2018}\medskip\\
Die zum Zeitpunkt dieser Anfertigung aktuellste Version ist Powershell 7.0, welche weiterhin plattformunabhängig von Microsoft angeboten wird~\cite{JoeyAiello032020}.


\section{Funktionsweise}
Die PowerShell wird unter den Systemadministratoren als der Nachfolger der \textit{cmd.exe} verstanden. Sie besitzt nicht nur die Befehle aus der bekannten Windows-Ausführungs-umgebung, sondern ermöglicht neben dem Ausführen auf der Konsole auch die Verwendung von Skripten in der Integrierten Skript Umgebung (ISE).~\cite[S.~7]{Schauland2016}\medskip\\
In der PowerShell heißen die ausführbaren Funktionen \textit{Commandlets}. Gemäß der objekt-orientierten Programmierung (\acrshort{oop}) lassen sich innerhalb dieser Commandlets wieder Befehle aufrufen, die dann \textit{Funktionen} genannt werden. Aus Anwendersicht existiert kein Unterschied zwischen Commandlets und Funktionen, weshalb die Unterscheidung in diesem Rahmen vernachlässigt werden kann~\cite[S.~34]{HolgerSchwichtenberg2018}.
Eine weitere Besonderheit der Powershell ist die ausschließliche Verwendung von Objekten.
\begin{quote}\textit{\glqq Bei der PowerShell ist alles ein Objekt. Alle Get-Commands geben Objekte zur{\"u}ck. Selbst eine harmlose Zeichenkette ist ein Objekt, die Members wie zum Beispiel eine \textit{Length-­}Eigenschaft besitzt.\grqq{}}~\cite[S.~15]{Monadjemi2017}\end{quote}
Der Mehrwert dieser Objekte liegt in der Weiterverarbeitung der gespeicherten Daten. Mithilfe der sog. \textit{Pipeline} werden die aufeinanderfolgenden Befehle miteinander verkettet. Die Ausgabe des vorangegangenen Befehls ist gleichzeitig die Eingabe des neuen Befehls. Die \textit{Pipeline} verbindet die Befehle miteinander, indem die Daten als Objekte übergeben und behandelt werden.\medskip\\Das folgende Beispiel verdeutlicht die Funktionsweise der Pipeline.
%\customcode{Get-Process | Sort-Object -Descending WS | Select -First 5}\\\\
\lstinputlisting[belowskip=-0.8\baselineskip,firstline=11,lastline=11,caption={Get-Process.ps1}]{Skripte/powershell2latex.txt}
Mit Get-Process werden alle laufenden Prozesse des hier verwendeten Betriebssystems aufgelistet. Bevor die Daten als Zeichenkette auf der Konsole ausgegeben werden, übergibt die Pipeline die Datenobjekte an den nachfolgenden Befehl. In diesem Fall folgt das Commandlet Sort-Object, welches die Prozesse nach ihrem \acrfull{ws}, also dem aktuell verwendeten Arbeitsspeicher, absteigend ordnet. Anschließend werden die geordneten Prozesse an das Commandlet Select übergeben, welches von allen in der Pipeline verfügbaren Objekten die ersten fünf auswählt. Als Zeichen auf der Konsole werden nach dieser Befehlskette die fünf Prozesse mit den größten Working Sets ausgegeben.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{Abbildungen/getprocess.PNG}
    \caption[PowerShell Get-Process Commandlet]{PowerShell Get-Process Commandlet (Quelle: eigene Aufnahme)} 
    \label{fig:GetProcess}
\end{figure}
Wie in \autoref{fig:GetProcess} zu sehen ist, wird nicht nur das Workingset der Prozesse ausgegeben, sondern auch alle anderen Eigenschaften, die sog. Member der Objekte, wie ID oder Name. Da die Daten der Befehle erst zur Ausgabe auf die Konsole in Zeichenketten umgewandelt werden, könnte man vorher auch nach Name oder ID der Prozesse filtern, sortieren oder andere Funktionen aufrufen.\medskip\\
An diesem Beispiel lässt sich die Notation der PowerShell-Befehle und damit der Aufbau eines Skripts gut erläutern. Die in \autoref{fig:GetProcess} gelb dargestellten Begriffe sind die Namen der Commandlets. Verbunden werden diese durch die Pipeline, welche mit einem vertikalen Strich verkörpert wird. Sollte ein Commandlet bestimmte Parameter benötigen, so werden diese nach Aufruf des Commandlets mit einem Bindestrich angegeben und danach deren Übergabewert definiert. Das Commandlet Sort-Object hat also den Parameter Descending, der hier mit dem \acrlong{ws} der Prozesse beschrieben wird.\medskip\\
Beim Aufruf von Commandlets und deren Parametern gibt es unterschiedliche Schreibweisen. Für den besseren Überblick über lange Befehlsketten empfiehlt es sich, die Namen der Commandlets so kurz wie möglich zu schreiben. Eine Alternative für den Befehl Sort-Object aus dem oberen Beispiel wäre Sort, wodurch kein Unterschied in der Ausführung entsteht, aber der Befehl etwas kürzer formuliert wird. Nähere Beschreibungen zu den Parametern finden sich im nächsten Abschnitt.
\section{Funktionen und Parameter}\label{sec:funcundPara}
Beim Aufruf eines PowerShell-Befehls wird ein Commandlet ausgeführt. Sobald dieses Commandlet innerhalb eines Skripts aufgerufen wird, entspricht das Verhalten einer Funktion. Wie im vorherigen Abschnitt bereits beschrieben, besteht aus Anwendersicht kein Unterschied zwischen Commandlet und Funktion. Beide Begriffe beziehen sich auf das Ausführen eines PowerShell-Befehls.\medskip\\
Eine Funktion kann durch das Übergeben von bestimmten Werten ihr Funktionsverhalten ändern. Möchte man eine Funktion aufrufen, und dabei z.B. Zahlen oder Zeichenketten an die Funktion übermitteln, so übergibt man diese als Parameter. Die Syntax dafür ist in folgendem Beispiel beschrieben:
%\customcode{Get-Testfunktion $"Hallo "$ $"Welt"$}\\\\
\lstinputlisting[belowskip=-0.8\baselineskip,firstline=9,lastline=9,caption={Beispielfunktion.ps1 erster Aufruf}]{Skripte/powershell2latex.txt}
Um der Funktion mit dem Namen \textit{Get-Testfunktion} zwei Werte als Parameter zu übergeben, werden diese nach Aufruf der Funktion angehängt. Das Standardverhalten bei der Parameterübergabe ist das Verwenden von Positionsparametern. In der Reihenfolge, in der die Parameter in der Funktion festgelegt sind, werden sie beim Aufruf auch zugeordnet. Alle weiteren Parameter werden als überflüssig eingestuft und deshalb ignoriert.\medskip\\
Möchte man die Reihenfolge bei der Parameterübergabe verändern, so gibt man vor dem Übergabewert zusätzlich den Namen des Parameters an, dem der Wert zugeordnet werden soll.
%\customcode{Get-Testfunktion -zweitesWort $"Welt"$ -erstesWort$ "Hallo"$}\\\\
\lstinputlisting[belowskip=-0.8\baselineskip,firstline=7,lastline=7,caption={Beispielfunktion.ps1 zweiter Aufruf}]{Skripte/powershell2latex.txt}
Beide Aufrufe der Beispielfunktion liefern das gleiche Ergebnis, welches, wie in \autoref{Funktionsdefinition} dargestellt, die einfache Kombination der Strings ist.
\lstinputlisting[label={Funktionsdefinition},belowskip=-0.8\baselineskip,firstline=1,lastline=5,caption={Beispielfunktion.ps1 Funktionsdefinition}]{Skripte/powershell2latex.txt}
Um die Effizienz im Aufruf von Funktionen zu erhöhen, können für Parameter oder ganze Funktionen Abkürzungen, sog. Aliase, verwendet werden. Solange die \mbox{PowerShell} eindeutig identifizieren kann, um welchen Parameter es sich handeln soll, wird die Syntax ohne Probleme zugelassen. Der Kreativität sind dabei keine Grenzen gesetzt, für die Lesbarkeit der Befehle lohnt es sich aber, etwas Zeit in den Aufruf einer Funktion zu investieren. Aus den Parametern \textit{erstesWort} und \textit{zweitesWort} in der obigen Beispielfunktion könnte ohne Probleme \textit{e} und \textit{z} werden. Sollten die Funktionen komplexer werden, könnten die Abkürzungen e und z zu Verwirrungen führen, da sie die Lesbarkeit des Befehls nicht fördern. Obwohl die Befehle dadurch deutlich kürzer werden, sollten Abkürzungen beim Funktionsaufruf mit Bedacht gewählt werden.
\cite[S.~53 f.]{Monadjemi2017}
\section{Erweiterbarkeit mit Modulen}\label{PSModules}
Um die Funktionalität der PowerShell zu erweitern, können sog. Module eingesetzt werden. Module spielen in der Shellumgebung eine wichtige Rolle, da die Shell selbst seit der PowerShell-Version 3.0 auf Modulen basiert~\cite[S.~73]{Monadjemi2017}. Jedes Modul muss sich in einem Verzeichnis befinden, in dem eine gleichnamige .psd1 oder .psm1 Datei enthalten ist. Sollen mehrere Versionen eines Moduls gleichzeitig vorliegen, so muss im Modulverzeichnis ein Versionsverzeichnis hinzugefügt werden, in dem dann die Skriptdateien der unterschiedlichen Versionen liegen. \cite[S.~8 f.]{Monadjemi2017}\medskip\\
Wird ein Modul zur Shell hinzugefügt, so werden alle Commandlets der PowerShell-Dateien im Modulverzeichnis geladen. Die dort definierten Aliase und Funktionen können nach Modulimport aufgerufen und ausgeführt werden. Meist sind darin auch Hilfebefehle enthalten, die dem Anwender das Modul genauer beschreiben.\medskip\\
Der Import von Modulen erfolgt grundsätzlich nur zur aktuellen Sitzung, also nur zur einmaligen Ausführung der PowerShell. Wird das Konsolenfenster zwischen zwei Befehlen geschlossen, müssen die Module erneut importiert werden. Da die \mbox{PowerShell} selbst auch auf Modulen basiert, werden bestimmte Verzeichnisse automatisch zur Ausführung importiert. Möchte man also ein Modul dauerhaft verwenden, so sollte man dessen Verzeichnis zur Umgebungsvariablen \textit{\$env:PSModulePath} hinzufügen. Die dort angegebenen Verzeichnisse werden von der PowerShell in regelmäßigen Abständen, aber vor allem zu Beginn der Ausführung durchsucht und alle enthaltenen Module importiert.~\cite[S.~76]{Monadjemi2017}\medskip\\
Im Gegensatz dazu ist es in speziellen Fällen auch erwünscht, bestimmte Module \textit{nicht} dauerhaft zu importieren. Dazu ist es möglich, mit dem Commandlet \textit{Import-Module} unter Angabe des Modulverzeichnisses das gewünschte Modul direkt zu importieren. Ohne das Modul manuell wieder entfernen zu müssen, steht es bei der nächsten Ausführung der PowerShell nicht mehr zur Verfügung.~\cite[S.~45]{HolgerSchwichtenberg2018}
%\lstinputlisting[caption={ImportModule.ps1}]{Skripte/importmodule.txt}
\lstinputlisting[belowskip=-0.8\baselineskip,firstline=13,lastline=13,caption={ImportModule.ps1}]{Skripte/powershell2latex.txt}
Mit Import-Module wird das Modul \textit{Testmodul} aus dem angegebenen Pfad importiert. Der optionale Parameter Verbose zeigt während des Imports die Zwischenschritte auf der Konsole an, bis das Modul vollständig importiert ist. Danach kann das Testmodul für die aktuelle Sitzung verwendet werden.
\section{PowerCLI mit VMware}\label{sec:PowerCLI}
VMware stellt für die Verwaltung der Managementsoftware vCenter Server neben den grafischen Benutzeroberflächen Webclient und vSphere-Client auch eine konsolenbasierte Lösung bereit. Ausgeführt wird dies als eine PowerShell-Erweiterung, welche allen PowerShell-Anwendern kostenlos zur Verfügung steht. Das Modul mit dem Namen \textit{Power\acrshort{cli}} stellt nach erfolgreichem Import diverse Commandlets zum Management der virtuellen Infrastruktur zur Verfügung. Neben der Abfrage von Systeminformationen lassen sich mit der Erweiterung auch Konfigurationsaufgaben, wie das Verschieben, Verändern, Starten oder Stoppen von Virtuellen Maschinen realisieren. Der größte Vorteil gegenüber den grafisch aufgearbeiteten Werkzeugen ist die Möglichkeit zur Verwendung von Skripten. Wie alle anderen PowerShell-Befehle auch, lassen sich die PowerCLI-Commandlets problemlos als Skript zusammenfassen und somit die Abwicklung bestimmter wiederkehrender Aufgaben am Virtualisierungssystem automatisieren.~\cite[S.~324 f.]{ThomasJoos2018}\medskip\\
Die Vielfältigkeit dieser Erweiterung kann mit folgendem Befehl aus \autoref{Auflistung} zur Auflistung aller Commandlets beschrieben werden.
\lstinputlisting[label={Auflistung},belowskip=-0.8\baselineskip,firstline=15,lastline=15,caption={Get-VICommand.ps1}]{Skripte/powershell2latex.txt}
Mit der Minimalkonfiguration von PowerCLI, welche im Wesentlichen aus dem Modul \textit{VMware.VimAutomation.Core} besteht, werden insgesamt 333 neue Commandlets zur PowerShell hinzugefügt, die ausschließlich für die Interaktion mit dem Virtualisierungssystem gedacht sind. Von diesen Commandlets beginnen 110 mit dem Indikator \textit{Get-}, welcher im PowerShell-Umfeld für das reine Abfragen von Informationen verwendet werden darf. Circa ein Drittel der Funktionalität von PowerCLI ist also auf die Informationsabfrage abgerichtet, wodurch diese Erweiterung ideal für automatisierte Überwachungswerkzeuge ausgelegt ist. Eine Auswahl der Commandlets aus PowerCLI ist in \autoref{tab:PowerClIBeispiele} im Anhang aufgeführt. Die Namen der Befehle geben einen Ausblick auf die enthaltene Funktionalität.
\section{PowerShell Remote}\label{PowerShellRemote}
Der Begriff PowerShell Remote steht für die Ausführung von PowerShell-Befehlen auf entfernten Computern. Dafür wird seit der PowerShell Version 2.0 der universelle Ansatz über den \acrfull{winrm}-Dienst bevorzugt. Dieser ermöglicht das Senden von PowerShell-Befehlen an das Remotesystem über HTTP. Der Quelltext wird über den Port 5985 an die entfernte PowerShell-Sitzung gesendet, die vorher vom Prozess \textit{wsmprovhost.exe} auf dem Zielsystem gestartet wurde. In dieser Sitzung wird die Anfrage ausgeführt und mittels eines serialisierten XML-Objekts an den Sender zurückgeschickt. Auf diese Weise ist jeder PowerShell-Befehl, der auf einem lokalen System ausführbar ist, auch remote einsetzbar. Um den WinRM-Dienst verwenden zu können, wird eine Konfigurationen des Zielsystems benötigt. Einerseits muss mittels PowerShell der Remoting Mechanismus auf dem entfernten Rechner eingerichtet werden, andererseits muss auf dem Zielsystem der entsprechende WinRM-Listener mit dazugehöriger Firewall-Ausnahme aktiviert werden. Dazu ist in den meisten Fällen eine Administratorberechtigung notwendig, die für die Remotesitzung aber ohnehin immer benötigt wird. In zentral administrierten Umgebungen wie z.B. in Virtualisierungsumgebungen kann diese Konfiguration mittels einer Gruppenrichtlinie durchgeführt werden, um alle betreffenden Computer gleichzeitig einzurichten. Die Ausführungen zur Gruppenrichtlinie in Windows-Umgebungen sind im \myRef{sec:GPO} aufgeführt. Sollen mehrere Befehle auf dem Remotesystem ausgeführt werden, so können Sitzungen für längere Zeit verwendet werden. Der Befehl New-PSSession startet die Sitzung auf dem Remotesystem unter Angabe des entfernten Computernamens, mit Remove-PSSession wird sie wieder geschlossen. Dazwischen kann an den Parameter Session jedes PowerShell Remotebefehls die aktuelle Sitzung angebunden werden, um sie für den Remotezugriff zu nutzen. Damit wird das erneute Öffnen und Schließen der Sitzung für jeden neuen Befehl nicht mehr benötigt, wodurch die Rechenzeit eines Skripts kürzer wird. Solange absehbar ist, dass nur einzelne Befehle, z.B. manuelle Abfragen außerhalb eines Skripts, auf dem Zielsystem ausgeführt werden sollen, empfiehlt sich die automatische Sitzungserstellung, die ohne spezielle Befehle für diesen einzelnen Remoteauftrag durchgeführt wird.
\cite[S.~862]{Weltner2013}
\chapter{Vorhandene Überwachungslösungen}\label{chap:monitor}
Die Systemverwaltung einer Virtualisierungsumgebung ist ein Tätigkeitsfeld, welches weltweit durch viele Administratoren abgedeckt und stetig verbessert wird. Dementsprechend gibt es zum Zeitpunkt dieser Arbeit bereits vorgefertigte Lösungen, die speziell für die Zustandserfassung und das Datenmonitoring von virtuellen Systemen gedacht sind. Im Folgenden werden zwei Beispiele dieser Lösungen vorgestellt und miteinander verglichen.
%\section{Vorstellen der Lösungen}
\section{Zabbix}
\textit{Monitor anything} (dt. alles überwachen) ist der Titel der Webseite des IT- Überwachungswerkzeuges \textit{Zabbix}. Die Open Source Lösung zum Datenmonitoring besteht im Wesentlichen aus drei Elementen, die nachfolgend kurz vorgestellt werden sollen. Auf den zu überwachenden Komponenten der IT-Infrastruktur werden die Zabbix-Agenten als Datensammler installiert. Diese erfassen die zuvor festgelegten Daten auf dem Zielsystem und übermitteln sie an die Serverkomponente. Der Zabbix-Server wird als eine Linuxmaschine ausgeführt. In einer Virtualisierungsumgebung empfiehlt es sich, diese Maschine als virtuelle Maschine auszuführen. Auf diesem virtuellen Server laufen die Daten in einer Datenbank zusammen und stehen für Auswertungen zur Verfügung. Die dritte Zabix Komponente ist die Benutzeroberfläche, die als Webseite die gesammelten Daten aufbereitet und darstellt. Diese Webseite ist neben der Anzeige auch für die Konfiguration der Zabbixinstallation verantwortlich. Anwender können z.B. intelligente Schwellwerte für Alarmbenachrichtigungen festlegen, interaktive Graphen anzeigen lassen, Berichte exportieren oder spezielle Benachrichtigungen konfigurieren. Die auf der Webseite dargestellten Daten basieren auf den zuvor konfigurierten Abfragen der Agenten. Daten die nicht abgefragt werden, können folglich auch nicht angezeigt werden. Zabbix hat daher die Agenten so ausgelegt, dass sie auf verschiedenen Plattformen so viele Daten wie möglich sammeln können und dabei sehr wenig Leistungsansprüche an das Zielsystem haben. \cite{ZabbixSIA2021,cubewerkGmbH2017}
\section{Paessler Router Traffic Grapher}
Unter dem Namen \textit{\acrfull{prtg}} versteht man die Monitoringsoftware der Firma Paessler AG, welche in der Überwachung von Netzwerk- und virtuellen Systemumgebungen sehr breit aufgestellt ist. Angeboten werden verschiedene Überwachungslösungen, die alle über flexible Benachrichtigungssysteme und Dashboards verfügen und somit als zentraler Überblick für viele Administratoren in der täglichen Arbeit unerlässlich werden. Der Zugriff auf die Verwaltung und Konfiguration der Software ist außerdem durch kostenlose Apps möglich, welche die Mobilität des Administrators beispielsweise bei einer Fehlersuche nicht einschränken. Die Software bedient sich zur Informationsabfrage sog. Sensoren, die im Sprachgebrauch der Paessler AG als Messpunkte für bestimmte Aspekte eines Geräts, z.B. der CPU Auslastung, definiert sind. Auf dem zu überwachenden Gerät wird keine zusätzliche Software installiert, sondern es werden nur bekannte Protokolle wie \acrshort{snmp} oder \acrshort{wmi} zur Abfrage des Systemzustands des Geräts verwendet. \cite{PaesslerAG2021}\medskip\\
Da \acrshort{prtg} keine quelloffene Software ist, wird für die Verwendung im Unternehmensumfeld ein Lizenzmodell benötigt. Dieses basiert auf den verwendeten Sensoren und orientiert sich nicht an den überwachten Geräten. Mit der kleinsten Lizenz, die über die freie Testversion hinaus geht, ist es möglich, bis zu 500 einzelne Sensoren zu überwachen. Bei überlicherweise zehn individuellen Sensoren pro Endgerät ist mit dieser Lizenz eine Überwachung von bis zu 50 Geräten möglich. Für die Lizenzierung ist es dabei unerheblich, ob die Sensoren in einem Netzwerkswitch einen Port, in der Firewall den Traffic, in einer SQL-Datenbank die Gesamteinträge oder die Lüfterdrehzahl des Virtualisierungshosts überwachen. Jeder dieser Sensoren kann für eine individuelle Auswertung verwendet werden, wenn PRTG auf ihn zugreifen kann. Zum Zeitpunkt dieser Anfertigung liegt diese unbefristete Lizenz preislich bei 1300€. \cite{PaesslerAG2021c}\medskip\\
Neben der Überwachung aller Netzwerkkomponenten, die durch einen Sensor abgebildet werden können, ist auch das Monitoring von VMware Umgebungen möglich. Mit passgenauen Sensoren, die auf die gesamte vSphere Virtualisierungsumgebung zugeschnitten sind, können sowohl die Performance der Hosts als auch die Anwendungsdaten der virtuellen Maschinen zu jeder Zeit im Auge behalten werden. Zusätzlich können für die historischen und aktuellen Überwachungsdaten detaillierte Berichte erzeugt werden, die je nach Bedarf in unterschiedlichen Zeitplänen und Dateiformaten automatisch zur Verfügung stehen.~\cite{PaesslerAG2021b}
\section{Einordnung der Aufgabe}
In den vorherigen Abschnitten wurden zwei Lösungen für das Datenmonitoring in Virtualisierungsumgebungen vorgestellt. Die beiden hier gezeigten Werkzeuge zur Systemüberwachung sind nicht die einzigen Lösungen, aus denen ein Administrator auswählen kann. Unter den unzähligen Alternativen hat sich in der Recherche jedoch herausgestellt, dass sich das Prinzip des IT-Monitorings bei allen Systemen in gewisser Weise ähnelt. So könnten hier noch weitere Lösungen wie beispielsweise Nagios, Grafana mit Telegraf oder direkte Angebote von VMware vorgestellt werden. Für das Konzept der Systemüberwachung ist es nicht relevant, ob die Software, wie z.B. PRTG, geschlossen in einem Lizenzpaket angeboten wird, oder wie Zabbix als Open Source Variante zur Verfügung steht - der Endeffekt für den Administrator, der im Folgenden vorgestellt wird, bleibt gleich.\medskip\\
\begin{comment}
Nagios\\
Grafana Visualisierung, Telegraf Datensammler\\
direkte Lösungen von VMware
Vergleich
Vorteil prtg: agentless monitoring --> geringe Last auf dem Zielgerät; durch Lizenzpaket auch Garantie bei Fehlern\\
nachteil: lizenzierung nach verwendeten Sensoren --> preis\\
vorteil zabbix: opensource\\
nachteil: skaliert schlecht bei sehr großen systemen\\
\end{comment}
Als Ergebnis haben alle Lösungen gemeinsam, dass eine Software auf dem Zielsystem durch verschiedene Abfragen oder Agenten die parametrierten Daten einholt und anschließend anschaulich aufbereitet. Die erfassten Daten könnten dann zyklisch von einem Administrator exportiert werden, um damit die Grundlage für eine Auswertung in Form von Berichten bereitzustellen.\medskip\\Der Nachteil dieser vorgestellten Lösungen ist meist die eingeschränkte Erweiterbarkeit. Sobald Aufgaben vom Monitoring der Systemumgebung abweichen und nicht in der Anwendung vorgesehen sind, wird eine Implementierung sehr aufwändig. Weiterhin erfüllen diese Lösungen zwar den Anspruch der Zustandserfassung, sie übertreffen die Anforderungen der hier betrachteten Anwendung aber deutlich, weil sie die gesamte Systemumgebung dauerhaft überwachen und somit große Datenmengen generieren. Die Anwendung soll aber nur den Momentanwert des Zustandes erfassen, wofür ein dauerhaftes Monitoring überqualifiziert ist.\medskip\\Die Lösungen vereint ebenfalls, dass auf dem Zielsystem in unterschiedlicher Weise eine Installation durchgeführt werden muss, die das Gesamtsystem nachhaltig verändert und deshalb in der geschlossenen PCS 7-Umgebung nicht gewünscht ist. Bei Zabbix sind es die Agenten, die auf den virtuellen Maschinen benötigt werden, bei PRTG ist es die Software allgemein, die installiert werden muss. Hinzu kommt, dass das Virtualisierungssystem vSphere die Systemdaten bereits erfasst, wodurch ein doppeltes Monitoring entstehen würde.\medskip\\
Um eine schlanke Anwendung für die Erfassung des Systemzustands zu entwickeln, wird also nicht auf vorhandene Überwachungswerkzeuge zurückgegriffen, sondern ein eigenes System aufgebaut. Die Vorgehensweise in der Entwicklung wird in den nächsten Kapiteln beschrieben.
\chapter{Vorbetrachtungen}
\section{Schnittstellenanalyse}
\begin{comment}
Schnittstellenanalyse am Virtualisierungssystem und Auswahl der Entwicklungsumgebung\\
Erörterung der Anwendungsumgebung\\
Rahmenbedingungen der Anwendung\\
\end{comment}
Das Nutzen der vorhandenen Managementsoftware vCenter Server ist eine Möglichkeit, um Informationen von den virtuellen Maschinen zu erhalten. Leider existiert in dieser geschlossenen Software keine vorgefertigte Funktion zum Exportieren der Daten, wodurch diese Variante nicht zur automatischen Datenauswertung beitragen kann. Diese Software wird als lizenziertes Modell der Firma VMware angeboten, was das Erweitern und Hinzufügen von Funktionen wie bei Open Source-Lösungen nicht ermöglicht. Der Webclient von vCenter-Server kann und sollte also für die momentane Überwachung und Administration der vSphere-Umgebung genutzt werden, da schneller auf Warnungen und Alarme eingegangen werden kann. Zur allgemeinen Abfrage des Systemzustandes muss eine andere Variante genutzt werden, die alle geforderten Daten mit einem Aufruf einholt und aufbereitet ausgibt. Zwar gibt es keine implementierte Lösung in vCenter Server, aber die Managementsoftware erlaubt den Zugriff auf ihre Daten mithilfe eines \acrfull{api}. Diese \acrshort{api} ermöglicht das Abfragen von Informationen zu den virtuellen Maschinen mittels Web-Requests. Neben der \acrshort{api} stellt VMware außerdem ein Kommandozeileninterface zur Verfügung, welches ebenfalls zur Automatisierung der virtuellen Umgebung genutzt werden kann. Diese Erweiterung der vCenter Server Funktionalität basiert auf dem PowerShell-Modul \textit{PowerCLI}, welches im \myRef{sec:PowerCLI} bereits beschrieben wurde.\medskip\\
Eine weitere Möglichkeit, Informationen von den virtuellen Maschinen abzurufen, ist der Zugriff mittels PowerShell-Remote. Dabei wird der Aspekt der Virtualisierung vernachlässigt und eine direkte Verbindung mit der Maschine hergestellt. Der Nachteil an dieser Variante ist, dass dadurch keinerlei Informationen des übergelagerten Virtualisierungssystems, sondern nur die der einzelnen virtuellen Maschine abgefragt werden können. Auf der virtuellen Maschine muss eine kompatible PowerShell-Version installiert sein und zudem der Zugriff über das Netzwerk möglich sein. Die genauen Voraussetzungen für einen PowerShell-Remotezugriff sind in \myRef{PowerShellRemote} beschrieben. Der Vorteil am Remotezugriff durch PowerShell ist das native Ausführen, ohne zusätzliche Module oder Erweiterungen installieren zu müssen. Alle benötigten Funktionen sind bereits in der PowerShell enthalten und müssen nur in richtiger Konfiguration genutzt werden. Da der Remotezugriff nicht an spezielle Virtualisierungsvarianten gebunden ist, könnten damit auch reale Maschinen, wie z.B. ThinClients in Operator- oder Engineeringstationen einer PCS 7-Anlage abgefragt werden.
\section{Gründe für die Verwendung von PowerShell}
Als Skriptsprache zur Entwicklung der Anwendung wird PowerShell ausgewählt. Die Gründe, weshalb unter den gegebenen Bedingungen PowerShell als optimale Herangehensweise zur Bearbeitung aller Aufgaben angenommen wird, werden nachfolgend genauer erläutert.\medskip\\
Bei der Auswahl einer Programmiersprache muss man sich verdeutlichen, welches Zielsystem mit der Anwendung angesprochen werden soll. Hier ist es die Überwachung bzw. die Abfrage einer PCS 7-Installation, welche grundsätzlich durch Windows-Umgebungen realisiert wird. Dabei ist es unerheblich, ob PCS 7 nicht, teilweise oder vollständig virtualisiert ist. Bei den Betriebssystemen, die für die Operator- und Engineeringstationen und Anlagenserver verwendet werden, handelt es sich um Windows Server. PCS 7-Neuanlagen werden nach aktuellem Stand mit der Windows Server Version 2019 ausgestattet. In Bestandsanlagen können auch noch ältere Versionen vorhanden sein. Neben vielen anderen Gemeinsamkeiten haben alle Windows Server seit der Version 2008 R2 gemeinsam, dass bereits eine PowerShell Version vorinstalliert ist. Für die Verwendung der Anwendung kann davon ausgegangen werden, dass auf dem Großteil der Zielgeräte eine kompatible PowerShell-Version zur Verfügung steht, die ohne zusätzliche Installationen genutzt werden kann. PowerShell ist auf den Systemen nicht nur vorinstalliert, sondern wird auch in der Zukunft fester Bestandteil der Windows Umgebung sein. Dies geht aus dem klaren Bekenntnis von Microsoft zur PowerShell hervor, womit unter anderem auch die zukünftige Weiterentwicklung und der Support der Skriptsprache garantiert wird \cite{JoeyAiello032020}.\medskip\\
Wie in \myRef{PSModules} bereits beschrieben, verfügt die PowerShell über eine einfache Erweiterbarkeit mithilfe von Modulen. Damit können vorgefertigte oder selbst entwickelte Erweiterungen unkompliziert zur PowerShell hinzugefügt werden. Eine dieser Erweiterungen ist das Modul PowerCLI, welches die Verbindung zur Managementsoftware vCenter Server herstellen kann. Die PowerShell kann also so konfiguriert werden, dass auch Informationen vom vCenter Server abgefragt und verarbeitet werden können. Neben den bereits vorhandenen Werkzeugen zur Administration, Verwaltung und Konfiguration des lokalen Systems wird mit dem Erweiterungsmodul auch die Schnittstelle zum VMware-System bedient. Für die Interaktion mit vCenter Server muss also keine eigene \acrshort{api} entwickelt werden, sondern es können bereits vorhandene Möglichkeiten genutzt werden, wodurch der Entwicklungsaufwand deutlich reduziert wird. Im Gegensatz zu den im \myRef{chap:monitor} vorgestellten Lösungen ist der PowerShell-Ansatz also auf hohem Grad konfigurierbar, was die Flexibilität der Anwendung enorm steigert.\medskip\\
Ein weiterer Vorteil an der Verwendung von PowerShell ist die bereits in die Skriptsprache integrierte Remote-Funktionalität, wodurch der Zugriff auf entfernte Rechner im Netzwerk ermöglicht wird. Eine manuelle Verbindung mit dem jeweiligen Rechner oder der virtuellen Maschine ist nur noch für direkte Arbeiten daran notwendig, weil auch aus der Ferne auf die Systeminformationen zugegriffen werden kann. Für die Ausführung der Anwendung ist dies eine enorme Zeitersparnis, da Informationen unkompliziert eingeholt werden können, ohne eine lokale Verbindung herstellen zu müssen.\medskip\\
Die PCS 7-Installation, deren Zustand hier erfasst werden soll, besteht ausschließlich aus Windows-Betriebssystemen, die problemlos von der PowerShell unterstützt werden. In anderen Virtualisierungsumgebungen ist es jedoch denkbar, dass unterschiedliche Betriebssysteme auf den virtuellen Maschinen zum Einsatz kommen. Auch dafür bietet die PowerShell eine Lösung, denn mit PowerShell Core lassen sich die Skripte plattformunabhängig ausführen. Die Voraussetzung dafür ist natürlich, dass PowerShell Core auf den abgezielten Systemen bereits installiert ist.
\begin{comment}
\begin{compactitem}
    \item alles Windows Umgebungen, PS vorinstalliert, zukunftssicher (wird nicht abgelöst wie FlashPlayer z.b. Stand heute, klares Bekenntnis von Microsoft zur PS), keine Installationsfreigabe notwendig (Genehmigungsprozess)
    \item plattformübergreifend möglich (auch evtl. Linux distributionen können interagieren)
    \item Remote Funktionalität (Fernzugriff auf Rechner mit PS)
    \item PS ist auf Systemadministratoren abgerichtet: viele Funktionen für Administration, Verwaltung, Konfiguration von Systemen
    \item mit Modulen Erweiterbar; öffentliches Repository
    \item auf höchstem Grad konfigurierbar, da kein standardisiertes Tool wie die vorher vorgestellten
    \item vorhandene Schnittstelle zu VMware kann genutzt werden (keine eigene API Entwicklung notwendig)
\end{compactitem}
\end{comment}
\newpage
\section{Rahmenbedingungen}\label{sec:Rahmenbedingungen}
Bei der Entwicklung einer Anwendung sollte sich der Entwickler die Rahmenbedingungen der Anwendung bewusst machen. Dabei sollte er sich unter anderem folgende Fragen stellen:
\begin{enumerate}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item Was soll die Anwendung erreichen?
    \item Auf welchem Zielsystem soll die Anwendung eingesetzt werden?
    \item Wer ist typischer Anwender?
    \item Wann und wofür wird die Anwendung genutzt?
\end{enumerate}
1. \textit{Was soll die Anwendung erreichen?}\\
Die Anwendung hat das klare Ziel, vorhandene und neu zu entwickelnde Softwarewerkzeuge zu einem gemeinsamen Skript zusammenzufügen. Die Skripte sollen den Zustand eines Virtualisierungssystems erfassen und darstellen können. Der Fokus der Anwendungsentwicklung liegt also nicht auf einer besonders ansprechenden Benutzer-oberfläche, sondern auf der Funktionalität. Die Anwendung soll außerdem nicht zu Werbezwecken dienen, um beispielsweise Kunden für ein Geschäft zu akquirieren. Das Ziel ist vielmehr, den Aufwand für sich wiederholende Aufgaben durch Automatisierung zu reduzieren und gleichzeitig einen Gesamtüberblick über den Systemzustand der Virtualisierungsumgebung zu erlangen. Weiterhin soll der Fokus auf der Datenabfrage liegen. Die erhobenen Daten sollen so effizient wie möglich dargestellt und analysiert werden. Auf interaktive Graphen oder ähnlich anspruchsvolle Datenvisualisierungen ist zu verzichten. Für individuelle Auswertungen sollen die Daten tabellarisch zur Verfügung stehen.\\Weiterhin sollen vorhandene Skripte, wie z.B. das Skript zur Freigabe der Windows Updates am WSUS, eingebunden werden, um ein zentrales Werkzeug für die Automatisierung am Virtualisierungssystem bereitzustellen. \medskip\\
2. \textit{Auf welchem Zielsystem soll die Anwendung eingesetzt werden?}\\
Die Anwendung soll auf die Interaktion mit dem Virtualisierungssystem der Firma VMware ausgelegt sein. Dieses System wird für die Realisierung einer PCS 7-Installation bei der Siemens AG genutzt. Dafür werden vor allem Windows Server Betriebssysteme eingesetzt, die auch gleichzeitig die Umgebung für die Anwendung darstellen. Da es sich bei diesen Systemen immer um speziell konfigurierte Installationen für die Ausführung von PCS 7 handelt, soll die Anwendung keine Veränderungen an diesen Systemen vornehmen oder verursachen.\medskip\\
3. \textit{Wer ist typischer Anwender?}\\
Die Anwendung ist für die ausschließliche Nutzung innerhalb der Siemens AG vorgesehen. Sie soll die Projektingenieure, die täglich am Virtualisierungssystem arbeiten, bei ihren Aufgaben unterstützen. Vom Anwender ist also ein solides Verständnis für Virtualisierungsumgebungen und im Allgemeinen auch der Umgang mit technischen Systemen zu erwarten.\medskip\\
4. \textit{Wann und wofür wird die Anwendung genutzt?}\\
Der Zustand des Virtualisierungssystems muss nicht zwingend in einem zeitkritischen Intervall abgefragt werden, da die Daten keine hohe Dynamik aufweisen. Gedacht ist die Ausführung der Anwendung zu Inbetriebnahmen oder Wartungen, welche üblicherweise halbjährlich durchgeführt werden.
\section{Weiterentwicklung und KnowHow-Schutz}
Für die zukünftige Weiterentwicklung der Anwendung muss ein Konzept erstellt werden, um die Vorgehensweise bei Neuimplementierungen oder Veränderungen von Funktionen zu beschreiben. Dafür ist eine Handlungsanweisung in Form einer \textit{Liesmich}-Datei in die Anwendung zu integrieren. Diese beschreibt den Funktionsumfang, sowie die technischen Voraussetzungen für die Nutzung der Anwendung. Weiterhin werden darin die einzelnen Funktionen an kurzen Beispielen gezeigt und empfohlene Anweisungen für die Ausführung gegeben.\medskip\\
Ein weiterer wichtiger Punkt ist der KnowHow-Schutz. Die Anwendung ist darauf abgezielt, in unterschiedlichen virtualisierten PCS 7-Anlagen bei Kunden der Prozessindustrie genutzt zu werden. Deshalb ist davon auszugehen, dass dort ein allgemeiner Zugriff auf die virtuellen Maschinen auch für andere Firmen besteht. Die im Zusammenhang mit dieser Arbeit entwickelten Aspekte und Lösungen sollen auf den Kundenanlagen vor fremder Ausführung und Einsicht geschützt werden.\newpage
\section{Bedienkonzept}\label{sec:Bedienkonzept}
Für die Interaktion mit dem Anwender benötigt die Anwendung eine intuitive Benutzeroberfläche. Die Vorgehensweise bei der Erstellung dieser Benutzeroberfläche soll in diesem Abschnitt unter dem Begriff \textit{Bedienkonzept} erläutert werden. Dieses Konzept ist für jede Art von Anwendung sehr unterschiedlich, wobei sich die generelle Struktur am Zweck der Anwendung und deren Bediener orientiert. Eine Anwendung, die für z.B. Werbezwecke auffallen soll, wird grafisch sehr anspruchsvoll und interaktiv, wie eine moderne Webseite gestaltet. Anwendungen, deren Wert durch die dahinterstehende Funktionalität gebildet wird, müssen nicht auffallen, sondern stehen dem Bediener mit schlichten, neutralen Oberflächen zur Seite.\medskip\\
In der Entwicklung der Anwendung zur Zustandserfassung des Virtualisierungssystems haben sich zwei mögliche Varianten für eine Bedienoberfläche herausgestellt. Für beide Varianten wurde ein \textit{\acrfull{poc}} erstellt, um die Vor- und Nachteile beider Oberflächen zu erkennen und diese Erkenntnisse in die Anwendungsentwicklung einfließen zu lassen.\medskip\\
Die erste Variante basiert auf dem grafischen Ansatz einer Benutzeroberfläche.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{Abbildungen/TestUI_small.PNG}\caption[Proof of Concept grafische Benutzeroberfläche]{\acrshort{poc} Grafische Benutzeroberfläche (Quelle: eigene Aufnahme)}
    \label{fig:TestUI}
\end{figure}
Für die Darstellung in \autoref{fig:TestUI} wurden die Objekte des .NET Frameworks innerhalb von PowerShell genutzt, um ein einfaches Hauptfenster als sog. Formular mit zwei Buttons zu erstellen. Die Integration der Funktionen von Formular und Button gestaltete sich sehr einfach, da die Methoden wie Größe, Platzierung und Aktion direkt aus der PowerShell beschrieben werden können. Für die Erstellung des Formulars in \autoref{fig:TestUI} wurden keine Bibliotheken oder ähnliches verwendet, da alle benötigten Erweiterungen bereits in der Minimalkonfiguration der PowerShell enthalten sind. Auch die oftmals in der Windowsumgebung verwendeten Dialogboxen können unkompliziert implementiert werden, um Informationen anzuzeigen.\\Beim Verwenden dieser Oberfläche hat sich allerdings schnell herausgestellt, dass die Ausgabe von Informationen, vor allem wenn diese in ihrer Struktur sehr variabel sind, eine aufwändige Implementierung erfordert. Das Konfigurieren der dafür benötigten Textfelder benötigt eine intensive Kenntnis über Länge und Aufbau eines Rückgabewerts, um diesen anschaulich formatiert auf dem Formular auszugeben. Eines dieser Textfelder wird hier für die Überschrift \textit{Siemens Test Tool} verwendet. Für solche statischen Ausgaben funktioniert das Darstellen des Textes umkompliziert. Wenn die Zeichenkette der Überschrift in der Länge variabel und mit verschiedenen Objekteigenschaften ausgestattet ist, so wird die Ausgabe der gesamten Information nahezu unmöglich, ohne dabei Zeichen abzuschneiden oder andere Objekte zu verschieben. Für eine saubere Implementierung einer solchen Ausgabe ist viel Programmieraufwand nötig, um alle Eventualitäten abzudecken und dem Anwender ein fehlerfreies Anwendungsbild zu liefern. Dies ist nicht unmöglich, aber nicht im Zeitrahmen dieser Bearbeitung realisierbar.\medskip\\Weiterhin hat die Darstellung dieses einfachen Formulars mit allen Eigenschaften und Methoden insgesamt ca. 100 Zeilen Quelltext benötigt. Wie man leicht in \autoref{fig:TestUI} erkennen kann, ist darin noch keinerlei wirkliche Funktion enthalten, sondern lediglich der Test der grafischen Oberfläche mittels PowerShell. Bei größeren Implementierungen wird der Quelltext selbst mit Verwendung der Strukturhilfen PowerShells deshalb schnell unübersichtlich. Weil alle Befehle der späteren Anwendung konsolenbasiert aufgebaut sind, bringt die grafische Benutzeroberfläche keinen wirklichen Mehrwert für den Anwender.\newpage 
\begin{wrapfigure}[]{r}{7.7cm}
    \centering
    \includegraphics[width=0.45\textwidth]{Abbildungen/PiHoleInstallationUbuntuSmall.png}\caption[PiHole Installation Konsolenausgabe]{PiHole Installation Konsolenausgabe\protect\footnotemark} 
    \label{fig:piHole}
\end{wrapfigure}
\footnotetext{Quelle: Stackoverflow, URL=\url{https://stackoverflow.com/questions/59091818/installing-pi-hole-in-docker-container}, abgerufen am 14.07.2021, Bildausschnitt verändert}
Die zweite Variante vernachlässigt die Eigenkonfiguration eines .NET Formulars vollständig und verwendet stattdessen die bereits vorhandene PowerShell-Konsole. Wie bei jeder anderen Konsole auch, werden ausschließlich Zeichenketten ausgegeben. \autoref{fig:piHole} zeigt am Beispiel der PiHole Installation unter Ubuntu die kreative Konsolenausgabe. Die Himbeere als Wiedererkennungsmerkmal des Raspberry Pi wird unter Verwendung von Zeichen und deren Farbveränderungen auf der Konsole ausgegeben. Die verwendeten Zeichenketten sind im Anhang im \myRef{sec:pihole} noch einmal als Text aufgeführt. Das Beispiel zeigt anschaulich, dass Konsolenausgaben auch einen grafischen Reiz haben können und die Informationen nicht nur als einfacher Text erscheinen, obwohl sie es faktisch sind.\medskip\\
\autoref{list:POCKonsole} stellt das \acrlong{poc} der zweiten Variante unter ausschließlicher Verwendung von Konsolenausgaben dar.
\lstinputlisting[label={list:POCKonsole},firstline=17,lastline=25,caption={PoC-Console.ps1}]{Skripte/powershell2latex.txt}
\newpage 
\begin{wrapfigure}[25]{l}{7.7cm}
    \centering
    \includegraphics[width=0.41\textwidth]{Abbildungen/PoC_Console2.PNG}\caption[Proof of Concept konsolenbasierte Benutzeroberfläche]{\acrshort{poc} konsolenbasierte Benutzeroberfläche (Quelle: eigene Aufnahme)}
    \label{fig:TestUIKonsole}
\end{wrapfigure}
Mit nur neun Zeilen Quelltext, die im \autoref{list:POCKonsole} aufgeführt sind, wird eine kurze Übersicht der laufenden Prozesse des lokalen Betriebssystems auf der Konsole ausgegeben (\autoref{fig:TestUIKonsole}). Wie man dem Quelltext entnehmen kann, werden für die Ausgaben der Informationen keine speziellen Konfigurationen benötigt. Sie werden einfach an das Commandlet Write-Host übergeben, welches unter anderem den Parameter \textit{-Foregroundcolor} (abgekürzt \textit{-F} dt. Vordergrundfarbe) hat, der die Vordergrundfarbe des Textes verändert. Sobald der Text nicht mehr statisch ist, sondern aufgrund der Objektnotation eine eigene Struktur aufweist, wie der Rückgabewert von \textit{Get-Process}, so übergibt die Pipeline bei fehlender Variablenzuordnung den Text automatisch an das Ausgabe-Commandlet. Dieses ist PowerShell-intern und kann beispielsweise mit \textit{-FormatTable} (abgekürzt FT dt. Format Tabelle) oder \textit{-FormatList} (abgekürzt FL dt. Format Liste) konfiguriert werden, um die Objekte als Tabelle oder Liste auszugeben. Für die Interaktion mit dem Anwender steht das Commandlet Read-Host zur Verfügung, welches Eingaben einliest und an Variablen bindet. Weiterhin können Warnungen und Fehlermeldungen dem Anwender direkt in der Konsole angezeigt werden, ohne ein zusätzliches Fenster zu benötigen.\medskip\\Dieses \acrlong{poc} hat gezeigt, dass die PowerShell-Konsole mit einfachen Möglichkeiten den Anforderungen der Anwendung gerecht wird, ohne dabei dem Nutzer wichtige Interaktionen vorzuenthalten. Die Entwicklung der Anwendung greift also ausschließlich auf die konsolenbasierten Aus- und Eingaben als Schnittstelle zum Anwender zurück.

\newpage

\chapter{Ergebnisse Anwendungsentwicklung}
\begin{comment}
\section{Was wurde erreicht?}
\begin{enumerate}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
    \item Toolkit als Zusammenfassung mehrerer Skripte
    \item Systemabfrage mit Generieren von Berichten als zentrales Bestandteil
    \item Prozessmonitor
    \item Bestätigen von Windows Updates
\end{enumerate}
\end{comment}
\section{Verzeichnis und Vorgehensweise}
Bei dem Zielsystem der Anwendung handelt es sich um das Virtualisierungssystem vSphere, welches unterschiedliche virtuelle Maschinen mit Windows Servern für  PCS 7 betreibt. Die Anwendung selbst wird auf einer der virtuellen Maschinen, auf der das Betriebssystem Windows Server in unterschiedlichen Versionen läuft, ausgeführt. Da es sich bei diesen virtuellen Maschinen um speziell für die Ausführung von PCS 7 konfigurierte Systeme handelt, darf die Anwendung keine Veränderungen vornehmen oder Einstellungen treffen. Sie soll nach erfolgreicher Ausführung auf der virtuellen Maschine keine Spuren hinterlassen, die das Systemverhalten ändern könnten. Aus diesem Grund wird die Anwendung bei Bedarf auf die virtuelle Maschine kopiert und in einem beliebigen lokalen Verzeichnis temporär gespeichert. Nach abgeschlossener Ausführung der Anwendung sollte der Anwender dieses Verzeichnis wieder löschen. Das Verzeichnis, welche alle für die Anwendung relevanten Dateien und Pfade enthält, ist in nachfolgender \autoref{fig:Anwendungsverzeichnis} dargestellt. Die Anwendung basiert auf einem PowerShell-Skript,
\begin{wrapfigure}[7]{l}{7.7cm}
    \centering
    \includegraphics[width=0.33\textwidth]{Abbildungen/Anwendungsverzeichnis.PNG}\caption[Anwendungsverzeichnis]{Anwendungsverzeichnis (Quelle: eigene Aufnahme)}
    \label{fig:Anwendungsverzeichnis}
\end{wrapfigure}
welches einerseits vorhandene Funktionen zusammenfasst und andererseits neuentwickelte Funktionen hinzufügt. Diese Funktionen werden durch PowerShell-Module verkörpert, welche sich im Anwendungsverzeichnis unter \textit{modules} befinden. Alle darin enthaltenen Module werden im ersten Schritt der Ausführung automatisch importiert. Im \myRef{PSModules} wurde das Verhalten der Module bei einem Import beschrieben. Weil die Module jeweils nur zur aktuellen PowerShell-Sitzung hinzugefügt werden, müssen sie nicht dauerhaft installiert werden und hinterlassen somit keine bleibenden Veränderungen am System.\medskip\\
Der zentrale Ort für alle Dateiablagen der Anwendung bildet der Ordner \textit{resources}, der sich genau wie \textit{modules} im Hauptpfad der Anwendung befindet. Hier werden die Dateien abgelegt, die im Laufe der Anwendungsausführung mit Informationen über das Virtualisierungsssytem beschrieben wurden. Einerseits liegen dort die Dateien, die als Zwischenschritt aus der Verbindung mit vCenter Server entstehen, andererseits wird dort auch am Ende der Systemabfrage der fertige Gesamtbericht abgelegt. Der Ordner \textit{resources} dient also für Dateiübergaben zwischen Anwender und Skript, die im Laufe der Anwendungsausführung benötigt werden.\medskip\\
Das empfohlene Vorgehen für die Anwendungsausführung wird mit folgendem Ablauf beschrieben:
\begin{enumerate}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
        \item Gesamtes Anwendungsverzeichnis auf Zielsystem kopieren
        \item PowerShellskript \textit{Toolkit.ps1} aus dem Anwendungsverzeichnis ausführen
        \item Generierte Berichte lokal sichern
        \item Anwendungsverzeichnis löschen
\end{enumerate}
Damit wird gewährleistet, dass keine Änderungen am System vorgenommen werden und die Anwendung dennoch Zugriff auf das Virtualisierungssytem hat.
\newpage
\section{Programmaufbau}
In diesem Abschnitt soll der Aufbau der Anwendung anhand einer allgemeinen Programmbeschreibung dargestellt werden. Für die Elemente der Flussbilder der nächsten Seiten gilt die unten stehende \autoref{fig:Legende} als Legende.\hspace*{\fill}
\begin{wrapfigure}[14]{l}{8cm}
    \centering
    \includegraphics[width=0.2\textwidth]{Abbildungen/Legende.PNG}\caption[Legende für Flussbilder ]{Legende für Flussbilder (Quelle: eigene Aufnahme)}
    \label{fig:Legende}
\end{wrapfigure}
\\\\
Start- oder Endzustand\\\\%\vspace{0.6cm}\\
Wartezustand (Benutzereingabe oder Verzögerung)\\\\%\vspace{0.6cm}\\
Funktion, Skript oder Vorgang innerhalb eines Skripts\\\\%\vspace{0.6cm}\\
Transitionen (Ja/Nein Entscheidungen)\\\\\\%\vspace{3cm}\\\\
Dateizugriff (lesend oder schreibend)\\\vspace{1.5cm}\\\\
Das folgende Flussbild in \autoref{fig:Ablauf} zeigt den Ablauf der Anwendung. Nachdem das Skript vom Anwender gestartet wurde, werden als erstes die Module aus dem Verzeichnis \textit{modules} importiert. Sollten Module bereits importiert sein, so werden sie beim initialen Import nicht berücksichtigt, um Zeit zu sparen. Nach erfolgreichem Modulimport wird die gesamte Textausgabe auf der Konsole mittels \textit{Clear-Host} zurückgesetzt, um einen definierten Platz für das Menü vorzubereiten. Dieses wird anschließend auf der Konsole angezeigt und der Anwender hat die Auswahl zwischen den vorgegebenen Menüpunkten. Sobald eine Auswahl im Menü getroffen wurde, wird die zugehörige Funktion aufgerufen und ausgeführt. Innerhalb der vier möglichen Funktionen \textit{Verbindung mit vCenter Server}, \textit{Systemabfrage}, \textit{Windows Updates} und \textit{Prozessmonitor} wird die Konsoleneingabe genutzt, um das Anwendungsverhalten zu beeinflussen, z.B. um in der Systemabfrage eine Textdatei zum Einlesen der Zielrechner auszuwählen.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Abbildungen/ApplicationFlow.png}
    \caption[Ablauf des Programms]{Ablauf des Programms (Quelle: eigene Aufnahme)} 
    \label{fig:Ablauf}
\end{figure}
Nachdem die Funktionen abgeschlossen sind, bestätigt der Anwender das Funktionsende, die Konsolenausgabe wird erneut gelöscht und die Anwendung kehrt zum Menü zurück. Wählt der Anwender im Menü den Punkt \textit{Beenden} aus, so wird das Skript beendet und das Hauptmenü nicht mehr angezeigt. Gleiches Verhalten wird durch die Eingabe der Tastenkombination \textit{CTRL-C} erreicht.\medskip\\
Die Anwendung ist so aufgebaut, dass aktive Verbindungen zu den verschiedenen Servern wie vCenter Server oder dem Windows Update Server nur solange aufrecht erhalten werden, wie sie auch tatsächlich benötigt werden. Am Beispiel der Verbindung mit vCenter Server lässt sich dies wie folgt erklären:\medskip\\
Sobald der Anwender den Abruf der Informationen vom vCenter Server startet, wird er um den Namen bzw. die IP-Adresse des Zielservers gebeten. Nachdem die Eingabe erfolgreich eingelesen wurde, muss sich der Anwender mit validen Zugangsdaten am vCenter Server anmelden. Mit der Anmeldung am Server wird die Verbindung aktiv. Anschließend werden von der Anwendung alle relevanten Daten der Virtualisierungsumgebung abgefragt und jeweils in .csv Dateien gespeichert. Sobald alle Informationen abgefragt wurden, wird die Verbindung mit vCenter Server wieder geschlossen. Die Anwendung kann nach dieser Abfrage weiterhin ausgeführt werden, ohne dass eine Verbindung zum vCenter Server benötigt wird. Die Verbindung zum vCenter Server ist also nur solange aktiv, wie sie von der Anwendung zwingend zur Ausführung benötigt wird. Mit diesem Prinzip wird verhindert, dass aktive Verbindungen über die Ausführung der Anwendung hinaus aufrecht erhalten werden und möglicherweise Einfluss auf zukünftige Verbindungsversuche haben.\medskip\\Der Nachteil dieser Methode ist, dass die abgerufenen Daten zwischengespeichert werden müssen. Die Informationen können also nicht einfach in einer PowerShell-Variable während der gesamten Ausführung der Anwendung gehalten, sondern müssen zwischendurch in einer Datei mit passendem Dateiformat abgelegt werden. Nachfolgende Funktionen, wie z.B. das Generieren von Berichten, müssen die Dateien dann erst wieder einlesen, um auf die Informationen zugreifen zu können. Dies hat den Vorteil, dass auch zu einem späteren Zeitpunkt noch Berichte erstellt werden können, ohne überhaupt eine Verbindung zum vCenter Server zu haben. Alles, was der Bericht als Eingangsdaten benötigt, ist in den .csv Dateien gespeichert. Der Anwender bestimmt, zu welcher Zeit er neue Informationen unabhängig von den generierten Berichten vom Server abfragt.\\Um eine Information über die letzte Abfrage vom vCenter Server zu haben, wird in der Statusleiste der Anwendung das Datum und die Uhrzeit der letzten Verbindung angezeigt. Ausgelesen wird diese Information aus dem Änderungszeitstempel einer .csv Datei, die bei jeder neuen Verbindung gespeichert wird. Damit hat der Anwender immer im Blick, %wie aktuell die Daten sind bzw.
auf welchen Stand sich die generierten Berichte beziehen.
\newpage
\section{Menü}\label{sec:menu}
Die Anwendung soll mehrere Funktionen innerhalb eines Skripts vereinen. Daher muss dem Anwender eine Möglichkeit unterbreitet werden, zwischen den Funktionen zu navigieren, um anschließend eine Auswahl der gewünschten Funktion zu treffen. Wie bereits im \myRef{sec:Bedienkonzept} beschrieben, eignet sich für eine skriptbasierte Anwendung auch eine konsolenbasierte Menüführung, die in diesem Abschnitt vorgestellt werden soll.\medskip\\
Um die Funktionalität eines Menü`s auf der Konsole darzustellen, wurde sich für ein horizontales, zeilengebundenes Menü entschieden. Jede Zeile entspricht dabei einem Menüpunkt, durch die mit den Pfeiltasten navigiert wird. Der aktuell ausgewählte Menüpunkt wird durch das Ändern der Textfarbe auf grün und ein \textit{X} am Zeilenanfang vom restlichen Menü hervorgehoben. \autoref{fig:Hauptmenü} zeigt das Hauptmenü der Anwendung, bei dem der Menüpunkt \textit{Systemabfrage} ausgewählt ist. Mit der
\begin{wrapfigure}[8]{l}{8 cm}
    \centering
    \includegraphics[width=0.5\textwidth]{Abbildungen/Menü.PNG}\caption[Hauptmenü]{Hauptmenü (Quelle: eigene Aufnahme)}
    \label{fig:Hauptmenü}
\end{wrapfigure}
Eingabetaste wird der aktuelle Menüpunkt ausgewählt und zum Untermenü dieses Punktes gewechselt. Darin eröffnen sich dem Anwender dann die für den Hauptmenüpunkt relevanten Auswahlmöglichkeiten. Die Anwendung kann mit dem Aufruf von \textit{Beenden} jederzeit beendet werden. Die Escapetaste wird zum Rücksetzen des Menü`s zum obersten Menüpunkt im Hauptmenü verwendet, mit Enter wird die Auswahl bestätigt. Um die Wiederverwendbarkeit des Menüs für zukünftige Projekte zu gewährleisten, wurden sämtliche menü-bezogenen Funktionen in einem PowerShell-Modul zusammengefasst. Das Modul wird zum Start der Anwendung importiert und könnte somit für andere Anwendungen ebenfalls verwendet werden. Auch innerhalb der Anwendung ist eine erneute Verwendung mit unterschiedlichen Menüpunkten möglich, was z.B. in der Auswahl von Dateien im Verzeichnis genutzt wurde.\medskip\\
 \begin{comment}
 \textbf{speziell konfigurierte Listen?} \textbf{Clear Host nach jedem menüaufruf?}\textbf{Handle Menu und DrawMenu als Unterfunktionen}\\
 \end{comment}
Dieses Menü ermöglicht eine einfache tastaturbasierte Navigation in einem ein- oder zweidimensionalen Menü.
Da das Menü nur die Auswahl aus den zuvor übergebenen Menüpunkten liefert, muss
der Rückgabewert des Menü`s anschließend anwendungsspezifisch weiterverarbeitet werden.
\newpage



\section{Systemabfrage}
Die Systemabfrage ist der zentrale Bestandteil der Anwendung, welcher auf die Erfassung des Systemzustandes abgerichtet ist. In diesem Abschnitt sollen die essentiellen Elemente der Abfrage sowie der generelle Ablauf beschrieben werden.
\subsection{Ablauf}
Die Systemabfrage beginnt mit dem Einlesen einer Textdatei, die die abzufragenden virtuellen Maschinen enthält. Standardmäßig wird dem Anwender die Auflistung aller .txt Dateien im Verzeichnis \textit{resources} als Auswahl vorgeschlagen. Der Anwender kann dann, wie in \myRef{sec:menu} beschrieben, aus den vorhandenen .txt Dateien mit den Pfeiltasten auswählen. Empfohlen ist an dieser Stelle, die Datei vmlist.txt auszuwählen, da diese direkt aus der Auflistung aller aktiven virtuellen Maschinen im vCenter Server besteht. Entscheidet sich der Anwender dazu, eine benutzerdefinierte Auswahl an virtuellen Maschinen abzufragen, so muss die Liste der virtuellen Maschinen vorher in einer .txt Datei im Ordner \textit{resources} gespeichert sein. Ist eine Datei ausgewählt, die mindestens den Namen einer virtuellen Maschine enthält, so wird mit der Abfrage begonnen. Für jede neue virtuelle Maschine wird ein PowerShell-Objekt erstellt, welches die relevanten Informationen als Eigenschaften speichert. Auf eine virtuelle Maschine wird nur dann zugegriffen, wenn diese den Verbindungstest besteht. Genauere Beschreibungen zum Ablauf des Verbindungstests sind im \myRef{sec:Fehler} aufgeführt. Die Abfrage des Systemzustands wird bei erfolgreichem Verbindungstest durchgeführt und die erfassten Informationen im Objekt gespeichert. Dieses Objekt wird anschließend an eine Liste von Objekten angefügt, die nach Abfrage aller virtueller Maschinen als .csv Datei exportiert wird. Der letzte Schritt in der Systemabfrage ist das Generieren eines Gesamtberichts, welches im \myRef{sec:Bericht} genauer erläutert wird. Danach ist die Abfrage abgeschlossen und die Anwendung kehrt in das Hauptmenü zurück.\newpage
Der oben beschriebene Ablauf der Systemabfrage ist im Flussbild der \autoref{fig:AblaufSystemabfrage} visualisiert.
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Abbildungen/Systemabfrage.png}
    \caption[Ablauf der Systemabfrage]{Ablauf der Systemabfrage (Quelle: eigene Aufnahme)} 
    \label{fig:AblaufSystemabfrage}
\end{figure}
Der Start- und Endzustand des hier dargestellten Flussbildes stellen den Übergang zwischen der Gesamtanwendung und der Systemabfrage dar. Wird im Hauptmenü der Anwendung (siehe \autoref{fig:Ablauf}) die Systemabfrage ausgewählt, so setzt der Anwendungsablauf hier im Startzustand der Systemabfrage fort. Sobald die Systemabfrage beendet wurde, gelangt die Anwendung nach Bestätigung des Anwenders zum Hauptmenü zurück.
\newpage
%detaillierte Ablaufbeschreibung für Remotezugriff
Die Vorgehensweise beim Remotezugriff auf virtuelle Maschinen soll an folgendem Beispiel zur Ermittlung der Zeitdifferenz aufgezeigt werden. Der zentrale Bestandtteil, des unter \autoref{AbfrageZeit} aufgeführten Quelltextes, ist der Invoke-Command in Zeile eins. Dieser ermöglicht das Ausführen eines Befehls auf dem entfernten Rechner unter Angabe zweier Parameter. Der erste Parameter ist die Session, welche die aktuelle Sitzung als aktive Verbindung zur virtuellen Maschine verkörpert und nach erfolgreichem Verbindungstest angelegt wurde. Der zweite Parameter ist der ScriptBlock, der den auszuführenden  PowerShell-Befehl an die virtuelle Maschine übergibt. Hier wird der Befehl Get-Date aufgerufen, der die aktuelle Systemzeit auf der virtuellen Maschine abfragt. Wie in \myRef{PowerShellRemote} beschrieben, werden die Informationen aus dem Scriptblock an den aufrufenden Rechner zurückgesendet, wodurch der gesamte Invoke-Command als Rückgabewert die Systemzeit der virtuellen Maschine hat. 
\lstinputlisting[belowskip=-0.8 \baselineskip,label={AbfrageZeit},firstline=1,lastline=3,caption={Abfrage der Zeitdifferenz}]{Skripte/BeispielSystemabfrage.txt}
Dieser Rückgabewert wird anschließend an den Endparameter des Commandlets New-TimeSpan gebunden, das mittels eines Start- und Endparameters die Zeitdifferenz zwischen zwei Zeitangaben bildet. Dadurch, dass die Zeit hier vom lokalen Rechner und vom Zielrechner angegeben wird, kann die Zeitdifferenz zwischen beiden Rechnern ermittelt werden. Dieser Wert wird dann in der Variable \$timediff gespeichert.\medskip\\
Die zweite Zeile von \autoref{AbfrageZeit} verdeutlicht die verwendete Objektnotation. Die Variable mit dem Namen \$obj\_systeminfo ist vom Typ PSCustomObject und wurde für die aktuell abzufragende virtuelle Maschine erstellt. Zu den bereits vorhandenen Eigenschaften wird in Zeile zwei mittels der PowerShell-Pipeline und des Commandlets Add-Member eine neue Eigenschaft (engl. Property) hinzugefügt. Diese Eigenschaft wird unter Angabe des Namens und des Wertes im Objekt gespeichert. Nach diesem Aufruf hat das Objekt also eine weitere Eigenschaft, die mit der Beschreibung \textit{Time\_Diff\_total\_ms} die Zeitdifferenz in Millisekunden zur virtuellen Maschine angibt. Da der Wert der Zeitdifferenz anschließend nicht mehr benötigt wird und eine doppelte Verwendung bei der nächsten Abfrage ausgeschlossen werden muss, wird die Variable \$timediff in Zeile drei geleert.
Das Vorgehen, welches hier schematisch an der Erfassung der Zeitdifferenz gezeigt wurde, wird auch für die weiteren Abfragen verwendet. Dabei wird im Scriptblock jedoch nicht Get-Date aufgerufen, sondern mittels Get-WmiObject der Zugriff auf die \acrfull{wmi}-Objekte gestattet. Auf den Windows-Betriebssystemen stehen diese Objekte zur Verfügung, die ihren Ursprung in der \acrlong{wmi} haben und gewisse Systemzustände repräsentieren. Für das Abfragen der Systeminformationen der virtuellen Maschinen wird auf folgende Objekte zugegriffen und deren Attribute ausgelesen:\\
\begin{table}[H]
\caption{WMI-Objekte und deren Eigenschaften in der Systemabfrage}
\label{tab:WMI-Objekte}
\begin{tabularx}{\textwidth}{X|l|X}
%\raggedleft
\makecell[l]{\textbf{WMI-Objekt}}&\textbf{Attribut bzw. Eigenschaft}&\textbf{Zuordnung}\\\hline
\makecell{win32\_logical\\disk}&\makecell[l]{Geräte-ID\\Festplattentyp\\Größe in GB\\Freier Speicher in GB}&\makecell[l]{Festplatten-\\kapazität}\\\hline
\makecell{win32\_operating\\system}&\makecell[l]{Gesamtspeicher (physisch/virtuell) in MB\\Freier Speicher (physisch/virtuell) in MB\\letztes Starten/Hochfahren\\Organisation\\Beschreibung\\Version}&\makecell[l]{Hauptspeicher\\(RAM)\\Allgemeine Info.}\\\hline
\makecell{win32\_network\\adapter}&\makecell[l]{Netzwerkadapter Name\\Service Name\\Geschwindigkeit in Bits/s}&\makecell[l]{Netzwerkadapter}\\\hline
\makecell{win32\_network\\adapter\\configuration}&\makecell[l]{IP-Adresse\\MAC-Adresse\\DHCP-Aktiviert\\IP-Gateway\\IP-Subnetz}&\makecell[l]{Netzwerkadapter-\\konfiguration}\\\hline
\makecell{win32\_processor}&\makecell[l]{CPU Name}&\makecell[l]{Prozessor}\\\hline
\end{tabularx}
\vspace{-2em}
\end{table}
Eine weitere Abfrage, die nicht auf die WMI-Objekte zugreift, ist die Informationsabfrage der Firewall. Dafür ist bei PowerShell-Versionen ab 4.0 das Commandlet Get-NetFirewallProfile implementiert, welches den Zustand der Firewall Domain, Privat und Öffentlich zurückgibt.\medskip\\
Die Rückgabewerte der WMI-Objekte und der Firewall werden, wie oben bei der Zeitdifferenz beschrieben, den jeweiligen PowerShell-Objekten zugeordnet und damit zur virtuellen Maschine zugewiesen.\medskip\\
Neben dem Remotezugriff ist der zweite essentielle Bestandteil der Systemabfrage das Einlesen der Informationen zu den virtuellen Maschinen aus .csv Dateien. Diese Dateien wurden vor Beginn der Systemabfrage vom vCenter Server abgefragt und unter \textit{resources} im Anwendungsverzeichnis gespeichert. Für die bessere Übersicht und Zusammenstellung des Gesamtberichts müssen die Informationen der einzelnen .csv Dateien den virtuellen Maschinen in der Systemabfrage zugeordnet werden. \autoref{ZuordnungVM} zeigt die Zuordnung am Beispiel allgemeiner Informationen, \autoref{ZuordnungSnapshots} am Beispiel von Snapshots.
\lstinputlisting[label={ZuordnungVM},firstline=7,lastline=10,caption={Zuordnung der vm.csv zu den VM Informationen}]{Skripte/BeispielSystemabfrage.txt}
\lstinputlisting[belowskip=-0.8\baselineskip,label={ZuordnungSnapshots},firstline=11,lastline=13,caption={Zuordnung der vm\_snapshots.csv zu den VM Informationen}]{Skripte/BeispielSystemabfrage.txt}
In den Variablen \$vm bzw. \$vm\_snapshots befinden sich jeweils alle Daten aus den .csv Dateien, die zu Beginn der Systemabfrage importiert wurden. Mithile des Commandlets Where-Object werden die Eigenschaften Name bzw. VM der Objekte mit der Variable \$endpoints verglichen. In \$endpoints[\$j] befindet sich der Name der aktuellen virtuellen Maschine, der für die Zurordnung benötigt wird. Where-Object durchsucht die Objekte nach Übereinstimmungen (-equals, abgekürzt -eq, dt. gleich) mit dem Namen der virtuellen Maschine und wählt anschließend nur die übereinstimmende Zeile aus der .csv Datei aus. Die Variablen \$current\_vm bzw. \$current\_vm\_snapshots halten anschließend nur noch die Informationen der aktuellen virtuellen Maschine, nicht mehr den gesamten Inhalt der .csv Datei. In \autoref{ZuordnungVM} zeigt sich erneut der Vorteil der PowerShell-Pipeline. Mithilfe von Select-Object werden nur die benötigten Eigenschaften der .csv Datei ausgewählt und für die Systemabfrage Irrelevantes ignoriert. Anschließend werden die gewünschten  Eigenschaften der Variable, welche vorher ausreichend selektiert wurden, zum bereits bekannten Objekt \$obj\_systeminfo hinzugefügt. Dies geschieht in \autoref{ZuordnungVM} mittels einer speziellen For-Schleife (Foreach), die über alle Eigenschaften des Objekts iteriert und jede einzeln hinzufügt. In \autoref{ZuordnungSnapshots} wird die manuelle Zuordnung ohne Schleife gewählt, da nur eine einzelne Eigenschaft hinzugefügt werden muss.\medskip\\
Die Vorgehensweise, die hier für die Zuordnung der Snapshots und allgemeinen Informationen der virtuellen Maschinen gezeigt wurde, kommt in gleicher Art und Weise auch für die Zuordnung der Statistiken vor. Je nach Überwachungslevel im vCenter Server werden unterschiedliche Werte wie Netzwerkaktivität oder Festplattenzugriff der virtuellen Maschinen aufgezeichnet. Bei den meisten virtuellen Maschinen werden folgende Statistiken aufgezeichnet, die auch im vCenter eingesehen werden können:
\begin{compactitem}
    \item Betriebszeit (in Tagen)
    \item CPU Nutzung (in \%, MHz)
    \item Speichernutzung (in \%)
    \item Festplattennutzung (in Kb/s)
    \item Netzwerknutzung (aller Adapter kombiniert, in Kb/s)
\end{compactitem}
Für einen optimalen Überblick über den zeitlichen Verlauf der vorliegenden Daten wurden aus den Durchschnittswerten aller verfügbaren Tage die drei folgenden Werte berechnet und den virtuellen Maschinen zugeordnet. Diese liefern für die jeweilige Statistik den Durchschnittswert am aktuellen Tag, in den letzten sieben Tagen und seit Start der virtuellen Maschine.\medskip\\
Die Information über die installierten Programme der virtuellen Maschinen wird aus der Registrierungsdatenbank (engl. registry) jeder virtuellen Maschine ausgelesen. 
\begin{compactitem}
    \item \path{Software\Microsoft\Windows\CurrentVersion\Uninstall}
    \item \path{Software\Wow6432Node\Microsoft\Windows\CurrentVersion\Uninstall}
\end{compactitem}
In den hier angegebenen Pfaden der Windows-Registry sind alle installierten Programme referenziert. Hier kann eine Information über Name, Installationsdatum, Version und ungefährer Größe des Programms gewonnen werden. Die Darstellung stimmt mit der Programmanzeige in \textit{Programme und Features} der Systemsteuerung von Windows überein. Die Informationen zu den Programmen werden ebenfalls in einer .csv Datei gespeichert.\medskip\\
Um die Konfiguration und den Zustand der verwendeten Hosts in der Virtualisierungsumgebung abzufragen, wird das Commandlet \textit{Get-VMHost} verwendet. Die daraus abgeleiteten Informationen werden direkt in einer .csv Datei gespeichert, um anschließend für den Systembericht zur Verfügung zu stehen. Die Abfrage der Hosts erfolgt ausschließlich durch die Informationen im vCenter Server, hier wird keine spezielle PowerShell-Remoteverbindung benötigt.
\begin{comment}
Voraussetzungen für den Zugriff: Thema Enable PS Remoting als GPO anlagenweit freigeben\\
schon in PowerShell Remote aufgeführt\\
\end{comment}
\subsection{Fehlervermeidung}\label{sec:Fehler}
In der Abfrage von sehr vielen unterschiedlichen Betriebssystemen ist es sehr wahrscheinlich, dass nicht alle Systeme auf dem gleichen Versionsstand sind. Vor allem bei älteren PowerShell-Versionen ist es möglich, dass bestimmte Funktionen zu dieser Version noch nicht hinzugefügt wurden und somit für die Anwendung noch nicht zur Verfügung stehen. Um eine fehlerhafte Ausführung zu verhindern und das Erscheinen von Fehlermeldungen bestmöglich zu unterdrücken, wird zu Beginn der Systemabfrage ein Verbindungstest mit der jeweiligen virtuellen Maschine durchgeführt. Dieser enthält den Test der Netzwerkverbindung mittels eines Pings, dessen Antwortzeit anschließend in den Gesamtbericht aufgenommen wird. Im Verbindungstest wird außerdem die PowerShell-Version abgefragt, um diese bei der Systemabfrage zu berücksichtigen. Virtuelle Maschinen, die eine bestimmte Funktion aufgrund veralteter Version nicht unterstützen, liefern bei Funktionsaufruf keinen Rückgabewert und haben deshalb im Gesamtbericht für diesen Wert keinen Eintrag. Das Aufführen der PowerShell-Version im Gesamtbericht dient für den Administrator als Hinweis, um zu erkennen, welche virtuellen Maschinen in nächster Zeit ein Update benötigen.\medskip\\Neben der Berücksichtigung in der Systemabfrage hat das Bestimmen der PowerShell-Version der virtuellen Maschine auch den Zweck der Zugriffsermittlung. Da die Abfrage der PowerShell-Version mitilfe von PowerShell-Remote auf die virtuelle Maschine zugreift, wird gewährleistet, dass der PowerShell-Remotezugriff richtig konfiguriert und einsatzbereit ist. Die nachfolgenden Befehle in der Ausführung der Anwendung basieren auf einer PowerShell-Remote Session, wodurch dieser Zugriff für die Systemabfrage unerlässlich ist. 
Alle virtuellen Maschinen, die den anfänglichen Verbindungstest nicht erfolgreich durchlaufen, werden in der Systemabfrage nicht berücksichtigt. Der Grund dafür ist, dass dadurch nicht auf Timeouts der einzelnen Funktionen gewartet werden muss, da sowieso kein Ping oder kein PowerShell-Zugriff möglich ist. Für den gesamten Anwendungsablauf bedeutet das eine erhebliche Zeitersparnis von ca. einer Minute pro virtueller Maschine. Um im Gesamtbericht trotzdem eine Auflistung der fehlgeschlagenen Zugriffe zu haben, werden alle virtuellen Maschinen mit falschem Verbindungstest an das Ende des Gesamtberichts angehängt.
\subsection{Erstellen von Berichten}\label{sec:Bericht}
Eines der Ziele der Anwendung ist es, die Abfrageergebnisse in einem Bericht darzustellen. Deshalb liefert die Systemabfrage für die einzelnen Kategorien der Abfrage jeweils eine .csv Datei. Es wurde sich für das Dateiformat .csv entschieden, da darin die Informationen bereits in Tabellenform vorliegen und dennoch mit einem normalen Texteditor bearbeitet werden können. Für die Auswertung der Daten können also alle Programme verwendet werden, die das Importieren von .csv Dateien unterstützen. Das im Officeangebot der Firma Microsoft enthaltene Excel bildet im betrieblichen Umfeld die Standardanwendung für Berichte und Auswertungen. Excel wird hier verwendet, da bereits eine Funktion zum Importieren von .csv Dateien vorhanden und deshalb die Installation von Drittanbietersoftware nicht zwingend notwendig ist. Bei den ersten Funktionstests der Anwendung hat sich herausgestellt, dass das Importieren der .csv Dateien in Excel eine sehr einfache aber dennoch zeitaufwändige Aufgabe ist. Deshalb wurde nach einer Lösung gesucht, die aus den vorhandenen .csv Dateien einen bereits fertig konfigurierten Excel-Bericht erstellt.\medskip\\
Der Umgang mit Excel-Objekten benötigt einen hohen Programmieraufwand, um alle dynamischen Längen und Strukturen der Daten sauber abzudecken. Eine Aufzeichnung des Arbeitsablaufs als Excel-Makro wäre eine denkbare Alternative gewesen, die aufgrund der folgenden Komplettlösung jedoch nicht bevorzugt wurde.\medskip\\
Wie für viele andere Herausforderungen in der Desktopautomatisierung gibt es auch für das vorliegende Problem eine PowerShell-Lösung in Form eines Moduls. Unter dem Namen \textit{ImportExcel} hat der Initiator Doug Finke zusammen mit seinen über 30 Mitwirkenden ein PowerShell-Modul entwickelt, welches die PowerShell mit der Erstellung von Excel-Dateien erweitert und somit die Automatisierung von Excel mittels PowerShell auf ein anwenderfreundliches Niveau hebt. Die Beschreibung des öffentlichen Repositories fängt den Funktionsumfang des Erweiterungsmoduls in wenigen Worten ein:
\begin{quote}\textit{\glqq \textbf{PowerShell + Excel = Better Together}}\\
\textit{Automate Excel via PowerShell without having Excel installed. Runs on Windows, Linux and MAC. Creating Tables, Pivot Tables, Charts and much more has just become a lot easier.\grqq{} }~\cite{Finke20210710}\end{quote}
Nachdem das Modul erfolgreich zur PowerShell-Sitzung hinzugefügt wurde, stehen dem Anwender neue Commandlets zur Verfügung. Das wichtigste Commandlet für die hier betrachtete Anwendung ist \textit{Export-Excel}, welches mit Pipeline-Anbindung direkt aus der PowerShell eine Excel-Datei erstellt.
\lstinputlisting[belowskip=-0.8 \baselineskip,label={Export-Excel1},firstline=1,lastline=2,caption={Export-Excel erstes Beispiel}]{Skripte/ImportExcel.txt}
Die in \autoref{Export-Excel1} in Zeile eins eingelesene .csv Datei wird in Zeile zwei direkt an Export-Excel übergeben. Mit Angabe des Datei- und Arbeitsblattnames wird in kürzester Zeit eine Excel-Datei erstellt, die das CSV-Format bereits korrekt interpretiert und in eine Tabelle umwandelt.
Um diese Tabelle zum gewünschten Bericht zu konfigurieren, müssen dem Commandlet Export-Excel folgende Parameter angefügt werden:\\
\begin{table}[H]
\caption{Parameter zum Konfigurieren des Berichts mittels Export-Excel}
\label{tab:ParameterExportExcel}
\begin{tabularx}{\textwidth}{l|l}
\makecell[l]{\textbf{Parameter}}&\makecell[l]{\textbf{Wirkung auf Tabelle}}\\\hline
\makecell[l]{AutoSize}&\makecell[l]{automatische Spaltenbreite}\\
\makecell[l]{AutoFilter}&\makecell[l]{automatischer Filter am Tabellenkopf}\\
\makecell[l]{NoNumberConversion}&\makecell[l]{keine Umwandlung von Zahlen/Ziffern; alles im Textformat}\\
\makecell[l]{FreezeTopRow}&\makecell[l]{Tabellenkopf eingefroren; oberste Zeile immer sichtbar}\\
\makecell[l]{BoldTopRow}&\makecell[l]{Tabellenkopf fettgedruckt}
\end{tabularx}
\vspace{-2em}
\end{table}
Der fertig konfigurierte Aufruf zum Generieren eines Berichts ist in \autoref{Export-Excel2} aufgeführt. Aus einer normalen .csv Datei wird mit diesem Aufruf unter minimalem Programmier- und Implementieraufwand eine funktionale Excel-Tabelle.
\lstinputlisting[belowskip=-0.8 \baselineskip,label={Export-Excel2},firstline=3,lastline=3,caption={Export-Excel zweites Beispiel}]{Skripte/ImportExcel.txt}
Um in der hier aufgeführten Vorgehensweise einen Bericht mit mehreren Tabellen zu erstellen, wird der Parameter \textit{WorksheetName} verändert, die neue .csv Datei in der Pipeline verwendet, aber der Pfad der Excel-Gesamtdatei gleich gelassen.
\lstinputlisting[belowskip=-0.8 \baselineskip,label={Export-Excel3},firstline=6,lastline=11,caption={Export-Excel drittes Beispiel}]{Skripte/ImportExcel.txt}
In \autoref{Export-Excel3} wird gezeigt, wie alle .csv Dateien, die in der Variable \$AllFiles gehalten werden, als Arbeitsblätter an eine gemeinsame Excel-Datei mit dem Namen \textit{Systembericht} angefügt werden.\medskip\\
Wie in der Excel-Anwendung auch, können für Zellen bedingte Formatierungen hinzugefügt werden, um Zahlenwerte nach gewissen Regeln farblich unterscheiden zu können. Das Modul \textit{ImportExcel} bietet dafür das Commandlet Add-ConditionalFormatting.
\lstinputlisting[belowskip=-0.8 \baselineskip,label={ConditionalFormatting},firstline=13,lastline=13,caption={Bedingte Formatierung in ImportExcel}]{Skripte/ImportExcel.txt}
Unter Angabe einer Excel-Range (dt. Reichweite) und des dazugehörigen Arbeitsblattes werden in \autoref{ConditionalFormatting} alle Zellwerte größer als 1000 mit einer roten Hintergrundfarbe versehen. Im Systembericht wird dies für das Hervorheben der Zeitdifferenz von mehr als 1000 ms verwendet, um eine schnelle Übersicht über Abweichungen der Systemzeit zu gewährleisten. In gleicher Weise wird die bedingte Formatierung für die Angaben des Festplatten- und Arbeitsspeichers erstellt. Auch bei der Anzahl von Snapshots der virtuellen Maschinen werden Werte hervorgehoben.\medskip\\
Der große Vorteil dieses Erweiterungsmoduls ist neben dem automatischen Export und dem Formatieren der Daten auch die Ausführung ohne eine Excel-Installation. Für die Funktionalität des PowerShell-Moduls wird kein Excel auf dem ausführenden Rechner benötigt, um die Excel-Datei zu erstellen. Die Berichte können direkt auf den Windows Servern generiert werden, ohne sie vorher auf einen Office-PC exportieren zu müssen.\medskip\\
Der fertig konfigurierte Systembericht enthält folgende Arbeitsblätter, die direkt aus den zugehörigen .csv Dateien erstellt wurden:\\
\begin{table}[H]
\caption{Aufbau des Systemberichts}
\label{tab:Systembericht}
\begin{tabularx}{\textwidth}{l|l}
\makecell[l]{\textbf{Arbeitsblatt}}&\makecell[l]{\textbf{Beschreibung}}\\\hline
\makecell[l]{DriveInfo}&\makecell[l]{Angabe der Festplattenkapazität der virtuellen Maschinen\\je Festplatte}\\\hline
\makecell[l]{Host}&\makecell[l]{Informationen über verwendete Hosts}\\\hline
\makecell[l]{InstalledPrograms}&\makecell[l]{alle installierten Programme der virtuellen Maschinen}\\\hline
\makecell[l]{NetworkInfo}&\makecell[l]{Netzwerkadapter, Verbindungskonfiguration, Netzwerk-\\statistik}\\\hline
\makecell[l]{SystemInfo}&\makecell[l]{Konfiguration der virtuellen Maschinen, Auslastungsstatistik,\\ Zuordnung, Zeitdifferenz, Firewall}
\end{tabularx}
\vspace{-2em}
\end{table}
Das Ergebnis der Berichtserstellung ist eine Excel-Datei mit dem Namen \textit{Systembericht}, die die in \autoref{tab:Systembericht} aufgeführten Arbeitsblätter enthält. Als eine zentrale Datei kann dieser Bericht optimal für das Verschaffen eines allgemeinen Überblicks oder für weiterführende Auswertungen genutzt werden. Die automatische Formatierung der Tabellen und das bedingte Formatieren von Zellen aufgrund ihrer Zellwerte erspart dem Anwender viel Konfigurationsaufwand, der ohne die vorliegende Automatisierung viel Zeit in Anspruch nähme.


\begin{comment}
\section{Performancevergleich}
überhautp notwendig? --> wahrscheinlich nicht
Invoke vs Session?\\
Vergleich der Zeiten
\end{comment}
\newpage
\section{Weitere Funktionen}\vspace{-4mm}
Die Anwendung sollte neben der Hauptfunktion der Systemabfrage auch die Sammelstelle für bereits vorhandene Skripte sein. Diese sollen hier kurz überblicksartig vorgestellt werden.\vspace{-7mm}%\textbf{Prozessmonitor}\\\
\subsection{Prozessmonitor}\vspace{-5mm}
Der Prozessmonitor ist eine Funktion, die einen einzelnen laufenden Prozess des Betriebssystems überwacht. Zu Beginn werden dem Anwender alle laufenden Prozesse unterbreitet, von denen einer ausgewählt werden soll. Nachdem eine zeitliche Angabe für das Abfrageintervall vom Anwender eingegeben wurde, beginnt die Funktion die Nutzung des Arbeitsspeichers dieses Prozesses abzufragen. Die erhobenen Daten werden mit dazugehörigem Zeitstempel in einer .csv Datei gespeichert. Das Skript läuft in einer Schleife, die nur von Anwendereingaben unterbrochen wird. Nachdem das Skript also einmal gestartet wurde, wird im angegebenen Zeitintervall die Arbeitsspeichernutzung des Prozesses erfasst und gespeichert. Benötigt wurde dieses Skript, weil ein bestimmter Prozess auf einer Kundenanlage mit steigender Betriebszeit des Servers zunehmende Arbeitsspeicherressourcen in Anspruch nahm. Dieses Skript ist im Praktikum, welches dieser Bearbeitung voranging, entstanden und wurde deshalb in diese Bearbeitung aufgenommen.\vspace{-7mm}
%\textbf{Windows Update Freigaben}\\\vspace{-10mm}
\subsection{Windows Update Freigaben}\vspace{-5mm}
Das in \myRef{sec:wsus} beschriebene Verhalten des \acrshort{wsus}-Servers geht mit der Notwendigkeit einher, dass alle zu installierenden Updates manuell vom Administrator für das System freigegeben werden müssen. Bei den dazu anstehenden Wartungen kommen nicht selten Freigaben von mehreren 100 Updates zusammen, welche einen enormen Zeitaufwand für den Administrator bedeuten. Das Skript soll diese Arbeit automatisieren und damit erleichtern. Nach erfolgreicher Verbindung mit dem \acrshort{wsus}-Server werden aus einer .csv Datei die Titel der Updates eingelesen. Anschließend wird geprüft, ob das Update bereits freigegeben wurde, und wenn nicht, die Freigabe erteilt. Nachdem alle Updates am \acrshort{wsus} überprüft wurden, bekommt der Administrator eine Auflistung über den Erfolg der Freigaben. Am WSUS wird unterdessen begonnen, diese Updates herunterzuladen.
Das Skript lag vor Bearbeitung als PowerShell-Skript vor und wurde für die Eingliederung in die Anwendung angepasst.
\chapter{Zusammenfassung und Ausblick}
Die Entwicklung der Anwendung wurde im Zusammenhang mit dieser Anfertigung erfolgreich abgeschlossen. Es wurde eine Anwendung entwickelt, die Ingenieure in der Zustandserfassung einer PCS 7-Virtualisierung unterstützt und zusätzlich vorhandene Skripte zusammenfasst. Um den Anforderungen an die Anwendung gerecht zu werden, musste sich in die komplexe Technologie der Virtualisierung eingearbeitet werden. Das Arbeiten in virtuellen Umgebungen ermöglicht eine schnelle und dynamische Anpassung an bestehende und neue Arbeitsprozesse, erfordert dabei aber gleichwohl ein hohes Maß an Verständnis der Infrastruktur. Im Hinblick auf die vielen verschiedenen Virtualisierungsmethoden mit unzähligen einzelnen Funktionen gilt der Grundsatz: \glqq easy to learn, hard to master\grqq{}. Es ist also vergleichsweise einfach, mit virtuellen Umgebungen zu arbeiten, jedoch erfordert es tiefgehende Kenntnisse, um das maximale Potential der virtuellen Infrastruktur zu nutzen.\medskip\\ 
Neben dem Konzept der Servervirtualisierung stellte sich die Skriptsprache PowerShell als essentieller Bestandteil der Anwendungsentwicklung heraus. Schnell zeigte sich, dass PowerShell im hohem Maße konfigurier- und erweiterbar ist und somit die optimale Entwicklungsumgebung für die Anwendung darstellt.
Die bereits vorhandenen Werkzeuge zur Administration und Verwaltung von Systemen wurden durch eigene Entwicklungen zur gesamten Systemabfrage des Zustands und die Realisierung eines Menüs mittels Modulen ergänzt. Mit den Erweiterungsmodulen PowerCLI und ImportExcel werden zusätzlich die essentiellen Funktionen der Anwendung, die Verbindung mit vCenter Server und das Exportieren von Excel-Berichten, hinzugefügt. Dem Anwender wird eine intuitive Schnittstelle geboten, die basierend auf einem selbst entwickeltem Bedienkonzept eine einfache Interaktion mit der Anwendung ermöglicht.\medskip\\
Nach Durchführung der Systemabfrage erhält der Anwender eine Übersicht über den aktuellen Zustand der gesamten Virtualisierungsumgebung. In diesem Bericht sind Aussagen zum Festplatten- und Arbeitsspeicher, der Prozessor- und Netzwerknutzung, sowie allgemeine Informationen der virtuellen Maschinen enthalten. Neben der Auslastung jeder einzelnen Maschine ist auch die Gesamtkonfiguration, also die Zuordnung zu den Virtualisierungshosts und die Gruppierung im Bericht aufgeführt.\medskip\\
%\chapter{Ausblick}\medskip\\
Die Entwicklung der Anwendung hat gezeigt, dass aufgrund der Verwendung von PowerShell die Erweiterungsmöglichkeiten sehr großen Umfang haben können. Für die Abfrage des Systemzustandes ist beispielsweise eine Implementierung des \acrfull{snmp} denkbar, womit Informationen von verschiedenen Netzwerkknoten eingeholt werden können. Die Informationsabfrage könnte damit weiter in Richtung Betriebssystemunabhängigkeit entwickelt werden und damit insgesamt breiter aufgestellt sein. PowerShell bietet für die Unterstützung von SNMP bereits vorgefertigte Module an. Die zweite Möglichkeit der Weiterentwicklung in Richtung Betriebssystemunabhängigkeit führt über PowerShell Core, womit das Ausführen von PowerShell auf deutlich mehr Betriebssystemen möglich ist.\medskip\\
Die Anwendung könnte weiter automatisiert werden, indem man das sog. Scheduling von Skripten verwendet. Damit könnte eine Zeitplanung für die Abfrage des Systemzustandes eingeführt werden, um die Ausführung der Anwendung ohne manuellen Start durchzuführen und die Berichte täglich, wöchentlich, monatlich oder in benutzerdefinierten Intervallen zu erstellen. Um die generierten Berichte nicht immer vom Virtualisierungssystem abrufen zu müssen, ist eine Verwendung eines E-Mail Benachrichtigungssystem denkbar. Dafür könnten die in PowerShell vorhandenen Commandlets zur Erstellung von .HTML Dateien verwendet werden, um die E-Mails in einem funktionalen aber dennoch optisch ansprechenden Format zu versenden.
Ähnlich könnte bei der weiterführenden Auswertung vorgegangen werden. Mittels HTML können die Berichte mit einem Übersichtsblatt (engl. Dashboard) versehen werden, womit die wichtigsten Informationen auf einen Blick dargestellt werden. Vor allem bei sehr großen Virtualisierungssystemen mit einer großen Anzahl an virtuellen Maschinen kann dies für eine verbesserte Übersicht hilfreich sein.\medskip\\
Neben dem Hinzufügen von neuen Funktionen der Anwendung könnten die bereits vorhandenen Funktionen weiter verbessert werden. Ein denkbarer Punkt ist dabei die Autovervollständigung von Eingaben. Die bereits vorhandene Befehlshistorie in der PowerShell könnte mit einer skriptinternen Historie erweitert werden. Damit werden dem Anwender z.B. bei der Verbindung mit vCenter Server die letzten Verbindungen vorgeschlagen, die dann nur noch ausgewählt und nicht erneut eingegeben werden müssen.\medskip\\ 
Weiterhin könnte das Importieren der Module in Zusammenspiel mit dem Menü verbessert werden. In der aktuellen Version ist es bei neuen Modulen erforderlich, die neuen Befehle entweder manuell einzugeben oder den Quelltext für die Erstellung des Menüs anzupassen. Beides sind für einen funktional-orientierten Anwender keine idealen Bedingungen. Der Modulimport könnte also insofern dynamisiert werden, dass die Module im Modulverzeichnis automatisch einen Hauptmenüpunkt darstellen, ohne individuelle Anpassungen am Menü direkt vornehmen zu müssen. Alle in den Modulen enthaltenen Funktionen könnten dann als Untermenü des jeweiligen Hauptmenüs angezeigt und ausgewählt werden. Bei der Weiter- oder Neuentwicklung eines Moduls ist dann nur das Hinzufügen zum Modulverzeichnis nötig, um die neuen Funktionen nutzen zu können.\medskip\\
Ein weiterer Verbesserungspunkt ist die Bereitstellung des Skripts für die Mitarbeiter der Siemens AG. Momentan wird das Skript als .zip Datei verteilt, was deutlichen Optimierungsbedarf aufweist. Ähnlich wie mit bekannten Repositories wie z.B. GitHub ist mit der PowerShell eine unternehmensinterne Bereitstellung möglich. Damit könnte der Zugang zum Skript verallgemeinert und die Zusammenarbeit an der Weiterentwicklung aufgrund der Versionsverfolgung erheblich verbessert werden.
\begin{comment}
für breitgefächertere/allgemeinere Abfragen unabhängig vom Betriebssystem: Implementieren von SNMP\\
automatische Abfrage mittels Scheduling, anschließend Generieren des Berichts im HTML Format, Versenden als Email\\
Dashboard\\
PowerShell Universal \\
Unternehmensinternes Repository für Bereitstellung des Skripts denkbar\\
Look and Feel verbessern: Autovervollständigung (Historie) der Verbindungen mit vCenter z.B.\\
Modulimport weiter dynamisieren --> jedes Modul wird als Hauptmenüpunkt aufgenommen, die einzelnen Commandlets könnten Untermenüpunkte sein: \\
z.B: Systemabfrage heißt das Modul = Hauptmenü; hat die Cmdlets Get-Systemabfrage und Get-Processmonitor = Untermenüpunkte --> neue Module automatisch im Menü ohne Code anpassen zu müssen; einfachere Entwicklung

Halbautomatisches Abfragen --> Daten manuell aus dem vCenter exportieren und dann Bericht erstellen lassen, Problem Datenstruktur wahrscheinlich nicht gleich\\\\
mittels PowerShell Core in der Zukunft auch plattformunabhängiges Arbeiten
\\\\
ähnlich wie mit Windows Updates --> stärker in Richtung PCS 7 analysieren, Toolkit um PCS 7 Analyse erweitern?
\end{comment}
%\chapter{Zusammenfassung}
\begin{comment}
Einblick in die Virtualisierung, Arbeiten in virtuellen Umgebungen\\
easy to learn, hard to master\\
PowerShell als Skriptsprache sehr hilfreich, übernimmt viele Funktionen, sehr gut konfigurierbar, kann auf Bedürfnisse des Anwenders gut eingehen\\
ImportExcel als sehr hilfreiches Arbeitsmittel in der Workflow automatisierung auch für andere Aufgaben (excel-bezogen)\\
\end{comment}